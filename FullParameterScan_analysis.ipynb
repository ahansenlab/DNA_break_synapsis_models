{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import bootstrapped.bootstrap as bts\n",
    "#import bootstrapped.stats_functions as bs_stats\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "from os import path\n",
    "import itertools \n",
    "from itertools import combinations \n",
    "\n",
    "# settings for making nice pdfs\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.sans-serif'] = \"Arial\"\n",
    "plt.rcParams['font.family'] = \"sans-serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define helper functions\n",
    "def round_sf(x,digits):\n",
    "    if x != 0:\n",
    "        x = float(np.format_float_positional(x, precision=digits, unique=False, fractional=False,trim='k'))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder_string = 'output_0310_tiling600_FullParamter_DenseDSBs_run'\n",
    "folders = [foldername for foldername in os.listdir('Data/') if base_folder_string in foldername]\n",
    "\n",
    "\n",
    "base_stochasticity = 1 # use to convert step to time\n",
    "\n",
    "for m in range(len(folders)):\n",
    "    data_dir = folders[m]\n",
    "    print(data_dir)\n",
    "    stats_file = [filename for filename in os.listdir('Data/'+data_dir) if filename.startswith(\"stats_df\")]\n",
    "\n",
    "    sep_proc_list = list(set([stats_file[i].split('stats_df_')[1].split('_superportion')[0] for i in range(len(stats_file))]))\n",
    "\n",
    "    superportion_list = list(set([stats_file[i].split('superportion')[1].split('_superproc')[0] for i in range(len(stats_file))]))\n",
    "    superportion_numerical_list = [float(a) for a in superportion_list]\n",
    "    superportion_list_sorted = [x for _,x in sorted(zip(superportion_numerical_list,superportion_list))]\n",
    "    superportion_numerical_sorted = [float(a) for a in superportion_list_sorted]\n",
    "    superproc_list = list(set([stats_file[i].split('superproc')[1].split('_ctcf')[0] for i in range(len(stats_file))]))\n",
    "    superproc_numerical_list = [float(a) for a in superproc_list]\n",
    "    superproc_list_sorted = [x for _,x in sorted(zip(superproc_numerical_list,superproc_list))]\n",
    "    superproc_numerical_sorted = [float(a) for a in superproc_list_sorted]\n",
    "    ctcf_list = list(set([stats_file[i].split('ctcf')[1].split('_dsb')[0] for i in range(len(stats_file))]))\n",
    "    ctcf_numerical_list = [float(a) for a in ctcf_list]\n",
    "    ctcf_list_sorted = [x for _,x in sorted(zip(ctcf_numerical_list,ctcf_list))]\n",
    "    ctcf_numerical_sorted = [float(a) for a in ctcf_list_sorted]\n",
    "    dsb_list = list(set([stats_file[i].split('dsb')[1].split('_superloading')[0] for i in range(len(stats_file))]))\n",
    "    dsb_numerical_list = [float(a) for a in dsb_list]\n",
    "    dsb_list_sorted = [x for _,x in sorted(zip(dsb_numerical_list,dsb_list))]\n",
    "    dsb_numerical_sorted = [float(a) for a in dsb_list_sorted ]\n",
    "    superloading_list = list(set([stats_file[i].split('superloading')[1].split('_bs')[0] for i in range(len(stats_file))]))\n",
    "    superloading_numerical_list = [float(a) for a in superloading_list]\n",
    "    superloading_list_sorted = [x for _,x in sorted(zip(superloading_numerical_list,superloading_list))]\n",
    "    superloading_numerical_sorted = [float(a) for a in superloading_list_sorted]\n",
    "    bs_list = list(set([stats_file[i].split('bs')[1].split('.csv')[0] for i in range(len(stats_file))]))\n",
    "    bs_numerical_list = [float(a) for a in bs_list]\n",
    "    bs_list_sorted = [x for _,x in sorted(zip(bs_numerical_list,bs_list))]\n",
    "    bs_numerical_sorted = [float(a) for a in bs_list_sorted]\n",
    "\n",
    "    if m == 0:\n",
    "        ctcf_bs_fp = np.zeros((len(folders),len(sep_proc_list),len(superportion_list),len(ctcf_list),len(dsb_list),len(superloading_list)))\n",
    "        ctcf_bs_success =  np.zeros((len(folders),len(sep_proc_list),len(superportion_list),len(ctcf_list),len(dsb_list),len(superloading_list)))\n",
    "        ctcf_bs_time0 =   np.zeros((len(folders),len(sep_proc_list),len(superportion_list),len(ctcf_list),len(dsb_list),len(superloading_list)))\n",
    "        load_constrain_ratio = np.zeros((len(folders),len(sep_proc_list),len(superportion_list),len(ctcf_list),len(dsb_list),len(superloading_list)))\n",
    "        extrusion_constrain_ratio = np.zeros((len(folders),len(sep_proc_list),len(superportion_list),len(ctcf_list),len(dsb_list),len(superloading_list)))\n",
    "    \n",
    "    count = 0 \n",
    "    for i in range(len(sep_proc_list)):\n",
    "        for j in range(len(superportion_list)):\n",
    "            for k in range(len(ctcf_list)):\n",
    "                for p in range(len(dsb_list)):\n",
    "                    for q in range(len(superloading_list)):\n",
    "                        proc = float(sep_proc_list[i].split('_proc')[1])\n",
    "                        sep = float(sep_proc_list[i].split('sep')[1].split('_proc')[0])\n",
    "                        if proc == 62.5:\n",
    "                            par_combo = sep_proc_list[i] + '_superportion' + superportion_list_sorted[j] + '_superproc' + str(proc*20) + '_ctcf' + ctcf_list_sorted[k] + '_dsb' + dsb_list_sorted[p]+ '_superloading' + superloading_list_sorted[q]+ '_bs' + bs_list_sorted[0]\n",
    "                        else:\n",
    "                            par_combo = sep_proc_list[i] + '_superportion' + superportion_list_sorted[j] + '_superproc' + str(int(proc*20)) + '_ctcf' + ctcf_list_sorted[k] + '_dsb' + dsb_list_sorted[p]+ '_superloading' + superloading_list_sorted[q]+ '_bs' + bs_list_sorted[0]\n",
    "\n",
    "                        filename = 'Data/' + data_dir + '/stats_df_' + par_combo + '.csv'\n",
    "\n",
    "                        if path.exists(filename):\n",
    "                            count+=1\n",
    "\n",
    "                            stats_df = pd.read_csv(filename)\n",
    "                            stats_df = stats_df.drop(columns='Unnamed: 0')\n",
    "                            stats_df_threshold1 = stats_df.loc[stats_df['threshold']==1]\n",
    "                            sep_proc_1st_pass = stats_df_threshold1['first_passage_time'].to_numpy()\n",
    "                            if len(sep_proc_1st_pass)>0:\n",
    "                                ctcf_bs_fp[m,i,j,k,p,q]=np.mean(sep_proc_1st_pass)*base_stochasticity/60 *2\n",
    "                            else:\n",
    "                                ctcf_bs_fp[m,i,j,k,p,q]=np.nan\n",
    "\n",
    "\n",
    "                            portion_df = pd.read_csv('Data/'+ data_dir + '/restrained_df_' + par_combo + '.csv')\n",
    "                            portion_df = portion_df.drop(columns='Unnamed: 0')\n",
    "                            portion_df_threshold1 = portion_df.loc[portion_df['threshold']==1]\n",
    "                            ctcf_bs_time0[m,i,j,k,p,q] = portion_df_threshold1['restrained proportion time0'].to_numpy()[0] * 100\n",
    "                            ctcf_bs_success[m,i,j,k,p,q] = portion_df_threshold1['repaired proportion'].to_numpy()[0] * 100\n",
    "                            \n",
    "                            \n",
    "                            ctcf_bs_capture[m,i,j,k,p,q] = ctcf_bs_success[m,i,j,k,p,q]/ctcf_bs_time0[m,i,j,k,p,q]\n",
    "                            \n",
    "                            D = 450 # average TAD size\n",
    "                            d = sep\n",
    "                            b = bs_numerical_sorted[0]\n",
    "                            a0 = superportion_numerical_sorted[j]\n",
    "                            s  = 20 #super vs normal proc ratio\n",
    "                            w = ctcf_numerical_sorted[k]\n",
    "                            r = dsb_numerical_sorted[p]\n",
    "                            F = superloading_numerical_sorted[q]\n",
    "                            v = 0.5\n",
    "                            \n",
    "                            constrain = proc/2/v #v = 0.5kb/second\n",
    "                            boundfraction = d/2/D+1/2+d/b/w/(a0*s*proc+(1-a0)*proc)-np.sqrt((d/2/D+1/2+d/b/w/(a0*s*proc+(1-a0)*proc))**2-d/D)\n",
    "                            alpha = a0*s/((1-a0)+a0*s)\n",
    "                            beta = 1-(1-boundfraction)**2\n",
    "                            proc_combined = beta*w*(a0*s*proc+(1-a0)*proc)+(1-beta)*(a0*s*proc+(1-a0)*proc)\n",
    "                            l = 0.5*(10**(-0.08238 + 0.7258*np.log10(proc_combined /sep) - \n",
    "                             0.2514*(np.log10(proc_combined /sep))**2 - \n",
    "                             0.003995*(np.log10(proc_combined /sep))**3 + \n",
    "                             0.03445*(np.log10(proc_combined /sep))**4 - \n",
    "                             0.01077*(np.log10(proc_combined /sep))**5 + \n",
    "                             0.001371*(np.log10(proc_combined /sep))**6 - \n",
    "                             6.472*10**(-5)*(np.log10(proc_combined /sep))**7)*sep)\n",
    "\n",
    "                            U = 10000 #dsb every 10kb\n",
    "                            load = proc*(2*F+U-2)*d/2/v/(F+l/2-1)/U\n",
    "                            constrain = proc/2/v\n",
    "                            extrusion = l/4/v\n",
    "                            load_constrain_ratio[m,i,j,k,p,q]= np.sqrt((alpha*load/(w*s*constrain)+(1-alpha)*load/(w*constrain))*(alpha*load/(w*s*r/(w*s+r)*constrain)+(1-alpha)*load/(w*r/(w+r)*constrain)))\n",
    "                            extrusion_constrain_ratio[m,i,j,k,p,q]= np.sqrt((alpha*extrusion/(w*s*constrain)+(1-alpha)*extrusion/(w*constrain))*(alpha*extrusion/(w*s*r/(w*s+r)*constrain)+(1-alpha)*extrusion/(w*r/(w+r)*constrain)))\n",
    "matplotlib.rcParams.update({'font.size': 22})       \n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20, 13))\n",
    "sc = plt.scatter(np.mean(extrusion_constrain_ratio,axis=0),np.mean(load_constrain_ratio,axis=0),c=np.mean(ctcf_bs_success,axis=0),cmap='viridis',s=75,edgecolors='k', vmin=0,vmax=100)\n",
    "plt.ylabel('Effective Extrusion Time / Effective Constrained Time')\n",
    "plt.xlabel('Effective Loading Time / Effective Constrained Time')\n",
    "cbar=plt.colorbar(sc)\n",
    "cbar.ax.get_yaxis().labelpad = 20\n",
    "cbar.ax.set_ylabel('Synpasis efficiency (%)', rotation=270)\n",
    "plt.tick_params(direction='out', length=12, width=2)\n",
    "plt.tick_params(axis='both', which='minor',length=6, width=2)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.savefig('Figures/'+'FullParameterScatter.pdf',format='pdf',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the indexes for parameter combinations that achieve >=95% synapsis efficiency\n",
    "perfect_index = np.argwhere(np.rint(np.mean(ctcf_bs_success,axis=0))>=95)\n",
    "\n",
    "perfect_index \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean synapsis time for the models achieving >=95% synapsis efficiency\n",
    "print(np.mean(ctcf_bs_fp,axis=0)[5, 3, 3, 1, 3])\n",
    "print(np.mean(ctcf_bs_fp,axis=0)[5, 3, 3, 2, 2])\n",
    "print(np.mean(ctcf_bs_fp,axis=0)[5, 3, 3, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KO prediction\n",
    "FoldReduction=np.zeros((len(perfect_index),perfect_index.shape[1]))\n",
    "OriginalEfficiency=np.zeros((len(perfect_index),perfect_index.shape[1]))\n",
    "NewEfficiency=np.zeros((len(perfect_index),perfect_index.shape[1]))\n",
    "for i in range(perfect_index.shape[1]):\n",
    "    for j in range(len(perfect_index)):\n",
    "        index = perfect_index[j]\n",
    "        newindex = np.copy(perfect_index[j])\n",
    "        newindex[i]=0\n",
    "        OriginalEfficiency[j,i]=np.mean(ctcf_bs_success,axis=0)[index[0],index[1],index[2],index[3],index[4]]\n",
    "        NewEfficiency[j,i] =  np.mean(ctcf_bs_success,axis=0)[newindex[0],newindex[1],newindex[2],newindex[3],newindex[4]]\n",
    "        FoldReduction[j,i]= 100*(np.mean(ctcf_bs_success,axis=0)[index[0],index[1],index[2],index[3],index[4]]-\\\n",
    "                             np.mean(ctcf_bs_success,axis=0)[newindex[0],newindex[1],newindex[2],newindex[3],newindex[4]])/np.mean(ctcf_bs_success,axis=0)[index[0],index[1],index[2],index[3],index[4]]\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "fig, axs = plt.subplots(1,1,figsize=(55, 15))\n",
    "\n",
    "# width of the bars\n",
    "barWidth = 0.2\n",
    "r1 = np.arange(5)\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "bars1 = np.mean(FoldReduction,axis=0)\n",
    "yer1 = stats.sem(FoldReduction,axis=0,nan_policy='omit')\n",
    "bars2 = np.mean(NewEfficiency,axis=0)\n",
    "yer2 = stats.sem(NewEfficiency,axis=0,nan_policy='omit')\n",
    "bars3 = np.mean(OriginalEfficiency,axis=0)\n",
    "yer3 = stats.sem(OriginalEfficiency,axis=0,nan_policy='omit')\n",
    "bars1_sorted = [x for _,x in sorted(zip(bars1,bars1),reverse=True)]\n",
    "yer1_sorted = [x for _,x in sorted(zip(bars1,yer1),reverse=True)]\n",
    "bars2_sorted = [x for _,x in sorted(zip(bars1,bars2),reverse=True)]\n",
    "yer2_sorted = [x for _,x in sorted(zip(bars1,yer2),reverse=True)]\n",
    "bars3_sorted = [x for _,x in sorted(zip(bars1,bars3),reverse=True)]\n",
    "yer3_sorted = [x for _,x in sorted(zip(bars1,yer3),reverse=True)]\n",
    "\n",
    "label  =[ 'Lowering processivity/separation to 0.5', 'Knockout long-lived LEFs', 'Knockout BE stabilization' , 'Knockout DSB stabilization', 'Knockout targeted loading']\n",
    "label_sorted = [x for _,x in sorted(zip(bars1,label),reverse=True)]\n",
    "\n",
    "# Create blue bars\n",
    "axs.bar(r1, bars3_sorted, width = barWidth, color = 'cyan', edgecolor = 'black', yerr=yer3_sorted, capsize=7, label=sep_proc_list[0],error_kw={'elinewidth':4,'capsize':10,'capthick':4})\n",
    "axs.bar(r2, bars2_sorted, width = barWidth, color = 'blue', edgecolor = 'black', yerr=yer2_sorted, capsize=7, label=sep_proc_list[0],error_kw={'elinewidth':4,'capsize':10,'capthick':4})\n",
    "\n",
    "\n",
    "# general layout\n",
    "axs.set_xticks([r + barWidth*1.5 for r in range(len(bars1))])\n",
    "axs.set_xticklabels(label_sorted)\n",
    "axs.set_ylabel('Synapsis efficiency(%)')\n",
    "plt.savefig('Figures/'+'KnockOut.pdf',format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficiency after KO\n",
    "np.round(bars2_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KO prediction for synapsis time\n",
    "FoldReduction=np.zeros((len(perfect_index),perfect_index.shape[1]))\n",
    "OriginalSynapsisTime=np.zeros((len(perfect_index),perfect_index.shape[1]))\n",
    "NewSynapsisTime=np.zeros((len(perfect_index),perfect_index.shape[1]))\n",
    "for i in range(perfect_index.shape[1]):\n",
    "    for j in range(len(perfect_index)):\n",
    "        index = perfect_index[j]\n",
    "        newindex = np.copy(perfect_index[j])\n",
    "        newindex[i]=0\n",
    "        OriginalSynapsisTime[j,i]=np.mean(ctcf_bs_fp,axis=0)[index[0],index[1],index[2],index[3],index[4]]\n",
    "        NewSynapsisTime[j,i] =  np.mean(ctcf_bs_fp,axis=0)[newindex[0],newindex[1],newindex[2],newindex[3],newindex[4]]\n",
    "        FoldReduction[j,i]= 100*(np.mean(ctcf_bs_fp,axis=0)[index[0],index[1],index[2],index[3],index[4]]-\\\n",
    "                             np.mean(ctcf_bs_fp,axis=0)[newindex[0],newindex[1],newindex[2],newindex[3],newindex[4]])/np.mean(ctcf_bs_fp,axis=0)[index[0],index[1],index[2],index[3],index[4]]\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "fig, axs = plt.subplots(1,1,figsize=(55, 15))\n",
    "\n",
    "# width of the bars\n",
    "barWidth = 0.2\n",
    "r1 = np.arange(5)\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "bars1 = np.mean(FoldReduction,axis=0)\n",
    "yer1 = stats.sem(FoldReduction,axis=0,nan_policy='omit')\n",
    "bars2 = np.mean(NewSynapsisTime,axis=0)\n",
    "yer2 = stats.sem(NewSynapsisTime,axis=0,nan_policy='omit')\n",
    "bars3 = np.mean(OriginalSynapsisTime,axis=0)\n",
    "yer3 = stats.sem(OriginalSynapsisTime,axis=0,nan_policy='omit')\n",
    "bars1_sorted = [x for _,x in sorted(zip(bars1,bars1),reverse=True)]\n",
    "yer1_sorted = [x for _,x in sorted(zip(bars1,yer1),reverse=True)]\n",
    "bars2_sorted = [x for _,x in sorted(zip(bars1,bars2),reverse=True)]\n",
    "yer2_sorted = [x for _,x in sorted(zip(bars1,yer2),reverse=True)]\n",
    "bars3_sorted = [x for _,x in sorted(zip(bars1,bars3),reverse=True)]\n",
    "yer3_sorted = [x for _,x in sorted(zip(bars1,yer3),reverse=True)]\n",
    "\n",
    "label  =[ 'Lowering processivity/separation to 0.5', 'Knockout long-lived LEFs', 'Knockout BE stabilization' , 'Knockout DSB stabilization', 'Knockout targeted loading']\n",
    "label_sorted = [x for _,x in sorted(zip(bars1,label),reverse=True)]\n",
    "\n",
    "# Create blue bars\n",
    "axs.bar(r1, bars3_sorted, width = barWidth, color = 'cyan', edgecolor = 'black', yerr=yer3_sorted, capsize=7, label=sep_proc_list[0],error_kw={'elinewidth':4,'capsize':10,'capthick':4})\n",
    "axs.bar(r2, bars2_sorted, width = barWidth, color = 'blue', edgecolor = 'black', yerr=yer2_sorted, capsize=7, label=sep_proc_list[0],error_kw={'elinewidth':4,'capsize':10,'capthick':4})\n",
    "\n",
    "\n",
    "# general layout\n",
    "axs.set_xticks([r + barWidth*1.5 for r in range(len(bars1))])\n",
    "axs.set_xticklabels(label_sorted)\n",
    "axs.set_ylabel('Synapsis Time(min)')\n",
    "plt.savefig('Figures/'+'KnockOut.pdf',format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synapsis time before KO\n",
    "bars3_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synapsis time after KO each mechanism\n",
    "bars2_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %increase in synapsis time upon lowering proc/sep ratio from 2 to 0.5\n",
    "(21.267600612315274-12.721139507149482)/ 12.721139507149482*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %increase in synapsis time upon knocking out DSB stabilization\n",
    "(17.74008007920686-12.721139507149482)/ 12.721139507149482*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %increase in synapsis time upon knocking out targeted loading\n",
    "(35.74008007920686-12.721139507149482)/ 12.721139507149482*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double knockout index\n",
    "double = [(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)]\n",
    "FoldReduction=np.zeros((len(perfect_index),10))\n",
    "OriginalEfficiency=np.zeros((len(perfect_index),10))\n",
    "NewEfficiency=np.zeros((len(perfect_index),10))\n",
    "for i,pair in enumerate(double):\n",
    "    for j in range(len(perfect_index)):\n",
    "        index = perfect_index[j]\n",
    "        newindex = np.copy(perfect_index[j])\n",
    "        newindex[pair[0]]=0\n",
    "        newindex[pair[1]]=0\n",
    "        OriginalEfficiency[j,i]=np.mean(ctcf_bs_success,axis=0)[index[0],index[1],index[2],index[3],index[4]]\n",
    "        NewEfficiency[j,i] =  np.mean(ctcf_bs_success,axis=0)[newindex[0],newindex[1],newindex[2],newindex[3],newindex[4]]\n",
    "        FoldReduction[j,i]= 100*(np.mean(ctcf_bs_success,axis=0)[index[0],index[1],index[2],index[3],index[4]]-\\\n",
    "                             np.mean(ctcf_bs_success,axis=0)[newindex[0],newindex[1],newindex[2],newindex[3],newindex[4]])/np.mean(ctcf_bs_success,axis=0)[index[0],index[1],index[2],index[3],index[4]]\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "fig, axs = plt.subplots(1,1,figsize=(55, 10))\n",
    "\n",
    "# width of the bars\n",
    "barWidth = 0.2\n",
    "r1 = np.arange(10)\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "bars1 = np.mean(FoldReduction,axis=0)\n",
    "yer1 = stats.sem(FoldReduction,axis=0,nan_policy='omit')\n",
    "bars2 = np.mean(NewEfficiency,axis=0)\n",
    "yer2 = stats.sem(NewEfficiency,axis=0,nan_policy='omit')\n",
    "bars3 = np.mean(OriginalEfficiency,axis=0)\n",
    "yer3 = stats.sem(OriginalEfficiency,axis=0,nan_policy='omit')\n",
    "bars1_sorted = [x for _,x in sorted(zip(bars1,bars1),reverse=True)]\n",
    "yer1_sorted = [x for _,x in sorted(zip(bars1,yer1),reverse=True)]\n",
    "bars2_sorted = [x for _,x in sorted(zip(bars1,bars2),reverse=True)]\n",
    "yer2_sorted = [x for _,x in sorted(zip(bars1,yer2),reverse=True)]\n",
    "bars3_sorted = [x for _,x in sorted(zip(bars1,bars3),reverse=True)]\n",
    "yer3_sorted = [x for _,x in sorted(zip(bars1,yer3),reverse=True)]\n",
    "\n",
    "label  =[ 'Lowering processivity/separation to 0.5+Knockout long-lived LEFs', 'Lowering processivity/separation to 0.5+Knockout BE stabilization','Lowering processivity/separation to 0.5+Knockout DSB stabilization', 'Lowering processivity/separation to 0.5+Knockout targeted loading','Knockout long-lived LEFs+Knockout BE stabilization', 'Knockout long-lived LEFs+Knockout DSB stabilization','Knockout long-lived LEFs+Knockout targeted loading','Knockout BE stabilization + Knockout DSB stabilization' ,'Knockout BE stabilization + Knockout targeted loading' , 'Knockout DSB stabilization + Knockout targeted loading']\n",
    "label_sorted = [x for _,x in sorted(zip(bars1,label),reverse=True)]\n",
    "\n",
    "# Create blue bars\n",
    "axs.bar(r1, bars3_sorted, width = barWidth, color = 'cyan', edgecolor = 'black', yerr=yer3_sorted, capsize=7, label=sep_proc_list[0],error_kw={'elinewidth':4,'capsize':10,'capthick':4})\n",
    "axs.bar(r2, bars2_sorted, width = barWidth, color = 'blue', edgecolor = 'black', yerr=yer2_sorted, capsize=7, label=sep_proc_list[0],error_kw={'elinewidth':4,'capsize':10,'capthick':4})\n",
    "\n",
    "\n",
    "# general layout\n",
    "axs.set_xticks([r + barWidth*1.5 for r in range(len(bars1))])\n",
    "axs.set_xticklabels(label_sorted, rotation=30)\n",
    "axs.set_ylabel('% Reduction in synapsis efficiency')\n",
    "plt.savefig('Figures/'+'DoubleKnockOut.pdf',format='pdf',bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
