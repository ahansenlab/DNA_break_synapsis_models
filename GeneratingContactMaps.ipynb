{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import os \n",
    "import shutil\n",
    "\n",
    "import contact_map_generator_from_shortest_path as cmgsp\n",
    "from contact_map_generator_from_shortest_path import contact_map_generator_from_SMC_list_and_DSBs\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(4000)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.colors as clr \n",
    "\n",
    "import timeit\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "from cooltools.lib.numutils import iterative_correction_symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SMC positions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder_string = 'output_0310_tiling600_2populationNonBypassingLEFs_GapMethod_SparseDSB_FullParamter_DenseDSBs_run'\n",
    "folders = [foldername for foldername in os.listdir('.') if base_folder_string in foldername]\n",
    "\n",
    "# Parameter combination giving more than 95% synapsis efficiency\n",
    "par_combo = ['sep125_proc250_superportion0.2_superproc5000_ctcf16_dsb4_superloading1000_bs0.5']\n",
    "\n",
    "time_point_list = [0]\n",
    "box_size = 2500 # number of monomers on each side of the DSB that we will make the contact map for\n",
    "short_list_beforeDSB = []\n",
    "for m in range(len(folders)):\n",
    "    for n in range(len(par_combo)):\n",
    "        data_dir = folders[m]\n",
    "        par = par_combo[n]\n",
    "        smc_file = data_dir + '/LEFcoordinates_' + par + '.npy'\n",
    "        SMCs = np.load(smc_file)\n",
    "\n",
    "        dsb_file = data_dir +'/DSB_boundary_coordinates.npy'\n",
    "        with open(dsb_file, 'rb') as infile:\n",
    "            DSBs = np.load(infile)\n",
    "            BEs = np.load(infile)\n",
    "\n",
    "        smcs_dict = {}\n",
    "        for t in time_point_list:\n",
    "            smcs_dict[t] = [(int(l),int(r)) for (l,r) in zip(SMCs[2*t,:],SMCs[2*t+1,:])]\n",
    "\n",
    "        for d in DSBs[1::2]: # d is the right DSB end\n",
    "            \n",
    "            shift_factor = d-box_size\n",
    "\n",
    "            for t in time_point_list: #smcs_dict.keys():\n",
    "                smcs = [(x[0]-shift_factor,x[1]-shift_factor) for x in smcs_dict[t] if (np.abs(x[0]-d)<=box_size)  and (np.abs(x[1]-d)<box_size)]\n",
    "                #short_list.append(smcs)\n",
    "                has_constraint = False\n",
    "                for x in smcs:\n",
    "                    if x[0]<box_size and x[1]>box_size:\n",
    "                        has_constraint = True\n",
    "                        break\n",
    "                if has_constraint==True:\n",
    "                    short_list_beforeDSB.append(smcs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 50\n",
    "nreps = 2\n",
    "for si, smcs in enumerate(short_list_beforeDSB):\n",
    "    dsb = [box_size-1,box_size]\n",
    "    L_tot = 2*box_size + base\n",
    "    \n",
    "    for rep in range(nreps):\n",
    "\n",
    "        m_samples1000_beforeDSB, c_samples1000_beforeDSB = contact_map_generator_from_SMC_list_and_DSBs(smcs,dsb,L_tot,base=base,nsamples=1000)\n",
    "\n",
    "        if rep == 0 and si == 0:\n",
    "            M_samples1000_beforeDSB = m_samples1000_beforeDSB\n",
    "            C_samples1000_beforeDSB = c_samples1000_beforeDSB\n",
    "        else:\n",
    "            M_samples1000_beforeDSB += m_samples1000_beforeDSB\n",
    "            C_samples1000_beforeDSB += c_samples1000_beforeDSB\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_new_samples1000_beforeDSB = np.zeros((100,100))\n",
    "C_new_samples1000_beforeDSB = np.zeros((100,100))\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        M_new_samples1000_beforeDSB[x//1,y//1] += M_samples1000_beforeDSB[x,y]\n",
    "        C_new_samples1000_beforeDSB[x//1,y//1] += C_samples1000_beforeDSB[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder_string = 'output_0310_tiling600_2populationNonBypassingLEFs_GapMethod_SparseDSB_FullParamter_DenseDSBs_run'\n",
    "folders = [foldername for foldername in os.listdir('.') if base_folder_string in foldername]\n",
    "\n",
    "# Parameter combination giving more than 95% synapsis efficiency\n",
    "par_combo = ['sep125_proc250_superportion0.2_superproc5000_ctcf16_dsb4_superloading1000_bs0.5']\n",
    "\n",
    "time_point_list = [6]\n",
    "box_size = 2500 # number of monomers on each side of the DSB that we will make the contact map for\n",
    "short_list = []\n",
    "for m in range(len(folders)):\n",
    "    for n in range(len(par_combo)):\n",
    "        data_dir = folders[m]\n",
    "        par = par_combo[n]\n",
    "        smc_file = data_dir + '/LEFcoordinates_' + par + '.npy'\n",
    "        SMCs = np.load(smc_file)\n",
    "\n",
    "        dsb_file = data_dir +'/DSB_boundary_coordinates.npy'\n",
    "        with open(dsb_file, 'rb') as infile:\n",
    "            DSBs = np.load(infile)\n",
    "            BEs = np.load(infile)\n",
    "\n",
    "        smcs_dict = {}\n",
    "        for t in time_point_list:\n",
    "            smcs_dict[t] = [(int(l),int(r)) for (l,r) in zip(SMCs[2*t,:],SMCs[2*t+1,:])]\n",
    "\n",
    "        for d in DSBs[1::2]: # d is the right DSB end\n",
    "\n",
    "            shift_factor = d-box_size\n",
    "\n",
    "            for t in time_point_list: #smcs_dict.keys():\n",
    "                smcs = [(x[0]-shift_factor,x[1]-shift_factor) for x in smcs_dict[t] if (np.abs(x[0]-d)<=box_size)  and (np.abs(x[1]-d)<box_size)]\n",
    "\n",
    "                has_constraint = False\n",
    "                for x in smcs:\n",
    "                    if x[0]<box_size and x[1]>box_size:\n",
    "                        has_constraint = True\n",
    "                        break\n",
    "                if has_constraint==True:\n",
    "                    short_list.append(smcs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of DSBs in the contact map\n",
    "len(short_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 50\n",
    "nreps = 2\n",
    "for si, smcs in enumerate(short_list):\n",
    "    dsb = [box_size-1,box_size] \n",
    "    L_tot = 2*box_size + base\n",
    "    \n",
    "    for rep in range(nreps):\n",
    "        m_samples1000, c_samples1000 = contact_map_generator_from_SMC_list_and_DSBs(smcs,dsb,L_tot,base=base,nsamples=1000)\n",
    "        if rep == 0 and si == 0:\n",
    "            M_samples1000_120min = m_samples1000\n",
    "            C_samples1000_120min = c_samples1000\n",
    "        else:\n",
    "            M_samples1000_120min += m_samples1000\n",
    "            C_samples1000_120min += c_samples1000\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_new_samples1000 = np.zeros((100,100))\n",
    "C_new_samples1000 = np.zeros((100,100))\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        M_new_samples1000[x//1,y//1] += M_samples1000_120min[x,y]\n",
    "        C_new_samples1000[x//1,y//1] += C_samples1000_120min[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=(M_new_samples1000/C_new_samples1000)/(M_new_samples1000_beforeDSB/C_new_samples1000_beforeDSB)\n",
    "corrected=iterative_correction_symmetric(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log2(corrected[0]),cmap='cividis',vmax=0.4,vmin=-0.4)\n",
    "# plt.hlines(50,0,100,linestyles=':')\n",
    "# plt.vlines(50,0,100,linestyles=':')\n",
    "plt.xlim([0,100])\n",
    "plt.ylim([0,100])\n",
    "\n",
    "plt.colorbar() \n",
    "plt.title(\"With DSB\")\n",
    "plt.savefig('Figures/'+'HiC_120min_2rep_1000samples_DividedByBeforeBSB_allTADs_vmax0.4_vmin-0.4_3rdParameterCombo_IterativeCorrected.pdf',format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder_string = 'output_0310_tiling600_2populationNonBypassingLEFs_GapMethod_SparseDSB_FullParamter_DenseDSBs_run'\n",
    "folders = [foldername for foldername in os.listdir('.') if base_folder_string in foldername]\n",
    "\n",
    "# Parameter combination giving more than 95% synapsis efficiency\n",
    "par_combo = ['sep125_proc250_superportion0.2_superproc5000_ctcf16_dsb4_superloading1000_bs0.5']\n",
    "\n",
    "time_point_list = [4]\n",
    "box_size = 2500 # number of monomers on each side of the DSB that we will make the contact map for\n",
    "short_list = []\n",
    "for m in range(len(folders)):\n",
    "    for n in range(len(par_combo)):\n",
    "        data_dir = folders[m]\n",
    "        par = par_combo[n]\n",
    "        smc_file = data_dir + '/LEFcoordinates_' + par + '.npy'\n",
    "        SMCs = np.load(smc_file)\n",
    "\n",
    "        dsb_file = data_dir +'/DSB_boundary_coordinates.npy'\n",
    "        with open(dsb_file, 'rb') as infile:\n",
    "            DSBs = np.load(infile)\n",
    "            BEs = np.load(infile)\n",
    "\n",
    "        smcs_dict = {}\n",
    "        for t in time_point_list:\n",
    "            smcs_dict[t] = [(int(l),int(r)) for (l,r) in zip(SMCs[2*t,:],SMCs[2*t+1,:])]\n",
    "\n",
    "        for d in DSBs[1::2]: # d is the right DSB end\n",
    "\n",
    "            shift_factor = d-box_size\n",
    "\n",
    "            for t in time_point_list: #smcs_dict.keys():\n",
    "                smcs = [(x[0]-shift_factor,x[1]-shift_factor) for x in smcs_dict[t] if (np.abs(x[0]-d)<=box_size)  and (np.abs(x[1]-d)<box_size)]\n",
    "\n",
    "                has_constraint = False\n",
    "                for x in smcs:\n",
    "                    if x[0]<box_size and x[1]>box_size:\n",
    "                        has_constraint = True\n",
    "                        break\n",
    "                if has_constraint==True:\n",
    "                    short_list.append(smcs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 50\n",
    "nreps = 2\n",
    "for si, smcs in enumerate(short_list):\n",
    "    dsb = [box_size-1,box_size] \n",
    "    L_tot = 2*box_size + base\n",
    "    \n",
    "    for rep in range(nreps):\n",
    "\n",
    "        m_samples1000, c_samples1000 = contact_map_generator_from_SMC_list_and_DSBs(smcs,dsb,L_tot,base=base,nsamples=1000)\n",
    "\n",
    "        if rep == 0 and si == 0:\n",
    "            M_samples1000_60min = m_samples1000\n",
    "            C_samples1000_60min = c_samples1000\n",
    "        else:\n",
    "            M_samples1000_60min += m_samples1000\n",
    "            C_samples1000_60min += c_samples1000\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_new_samples1000 = np.zeros((100,100))\n",
    "C_new_samples1000 = np.zeros((100,100))\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        M_new_samples1000[x//1,y//1] += M_samples1000_60min[x,y]\n",
    "        C_new_samples1000[x//1,y//1] += C_samples1000_60min[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=(M_new_samples1000/C_new_samples1000)/(M_new_samples1000_beforeDSB/C_new_samples1000_beforeDSB)\n",
    "corrected=iterative_correction_symmetric(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log2(corrected[0]),cmap='cividis',vmax=0.4,vmin=-0.4)\n",
    "plt.xlim([0,100])\n",
    "plt.ylim([0,100])\n",
    "\n",
    "plt.colorbar() \n",
    "plt.title(\"With DSB\")\n",
    "plt.savefig('Figures/'+'HiC_60min_2rep_1000samples_DividedByBeforeBSB_allTADs_vmax0.4_vmin-0.4_3rdParameterCombo_IterativeCorrected.pdf',format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder_string = 'output_0310_tiling600_2populationNonBypassingLEFs_GapMethod_SparseDSB_FullParamter_DenseDSBs_run'\n",
    "folders = [foldername for foldername in os.listdir('.') if base_folder_string in foldername]\n",
    "\n",
    "# Parameter combination giving more than 95% synapsis efficiency\n",
    "par_combo = ['sep125_proc250_superportion0.2_superproc5000_ctcf16_dsb4_superloading1000_bs0.5']\n",
    "\n",
    "time_point_list = [3]\n",
    "box_size = 2500 # number of monomers on each side of the DSB that we will make the contact map for\n",
    "short_list = []\n",
    "for m in range(len(folders)):\n",
    "    for n in range(len(par_combo)):\n",
    "        data_dir = folders[m]\n",
    "        par = par_combo[n]\n",
    "        smc_file = data_dir + '/LEFcoordinates_' + par + '.npy'\n",
    "        SMCs = np.load(smc_file)\n",
    "\n",
    "        dsb_file = data_dir +'/DSB_boundary_coordinates.npy'\n",
    "        with open(dsb_file, 'rb') as infile:\n",
    "            DSBs = np.load(infile)\n",
    "            BEs = np.load(infile)\n",
    "\n",
    "        smcs_dict = {}\n",
    "        for t in time_point_list:\n",
    "            smcs_dict[t] = [(int(l),int(r)) for (l,r) in zip(SMCs[2*t,:],SMCs[2*t+1,:])]\n",
    "\n",
    "        for d in DSBs[1::2]: # d is the right DSB end\n",
    "\n",
    "            shift_factor = d-box_size\n",
    "\n",
    "            for t in time_point_list: #smcs_dict.keys():\n",
    "                smcs = [(x[0]-shift_factor,x[1]-shift_factor) for x in smcs_dict[t] if (np.abs(x[0]-d)<=box_size)  and (np.abs(x[1]-d)<box_size)]\n",
    "\n",
    "                has_constraint = False\n",
    "                for x in smcs:\n",
    "                    if x[0]<box_size and x[1]>box_size:\n",
    "                        has_constraint = True\n",
    "                        break\n",
    "                if has_constraint==True:\n",
    "                    short_list.append(smcs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 50\n",
    "nreps = 2\n",
    "for si, smcs in enumerate(short_list):\n",
    "    dsb = [box_size-1,box_size] \n",
    "    L_tot = 2*box_size + base\n",
    "    \n",
    "    for rep in range(nreps):\n",
    "\n",
    "        m_samples1000, c_samples1000 = contact_map_generator_from_SMC_list_and_DSBs(smcs,dsb,L_tot,base=base,nsamples=1000)\n",
    "\n",
    "        if rep == 0 and si == 0:\n",
    "            M_samples1000_20min = m_samples1000\n",
    "            C_samples1000_20min = c_samples1000\n",
    "        else:\n",
    "            M_samples1000_20min += m_samples1000\n",
    "            C_samples1000_20min += c_samples1000\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_new_samples1000 = np.zeros((100,100))\n",
    "C_new_samples1000 = np.zeros((100,100))\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        M_new_samples1000[x//1,y//1] += M_samples1000_20min[x,y]\n",
    "        C_new_samples1000[x//1,y//1] += C_samples1000_20min[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=(M_new_samples1000/C_new_samples1000)/(M_new_samples1000_beforeDSB/C_new_samples1000_beforeDSB)\n",
    "corrected=iterative_correction_symmetric(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log2(corrected[0]),cmap='cividis',vmax=0.4,vmin=-0.4)\n",
    "plt.xlim([0,100])\n",
    "plt.ylim([0,100])\n",
    "\n",
    "plt.colorbar() \n",
    "plt.title(\"With DSB\")\n",
    "plt.savefig('Figures/'+'HiC_20min_2rep_1000samples_DividedByBeforeBSB_allTADs_vmax0.4_vmin-0.4_3rdParameterCombo_IterativeCorrected.pdf',format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder_string = 'output_0310_tiling600_2populationNonBypassingLEFs_GapMethod_SparseDSB_FullParamter_DenseDSBs_run'\n",
    "folders = [foldername for foldername in os.listdir('.') if base_folder_string in foldername]\n",
    "\n",
    "# Parameter combination giving more than 95% synapsis efficiency\n",
    "par_combo = ['sep125_proc250_superportion0.2_superproc5000_ctcf16_dsb4_superloading1000_bs0.5']\n",
    "\n",
    "time_point_list = [2]\n",
    "box_size = 2500 # number of monomers on each side of the DSB that we will make the contact map for\n",
    "short_list = []\n",
    "for m in range(len(folders)):\n",
    "    for n in range(len(par_combo)):\n",
    "        data_dir = folders[m]\n",
    "        par = par_combo[n]\n",
    "        smc_file = data_dir + '/LEFcoordinates_' + par + '.npy'\n",
    "        SMCs = np.load(smc_file)\n",
    "\n",
    "        dsb_file = data_dir +'/DSB_boundary_coordinates.npy'\n",
    "        with open(dsb_file, 'rb') as infile:\n",
    "            DSBs = np.load(infile)\n",
    "            BEs = np.load(infile)\n",
    "\n",
    "        smcs_dict = {}\n",
    "        for t in time_point_list:\n",
    "            smcs_dict[t] = [(int(l),int(r)) for (l,r) in zip(SMCs[2*t,:],SMCs[2*t+1,:])]\n",
    "\n",
    "        for d in DSBs[1::2]: # d is the right DSB end\n",
    "\n",
    "            shift_factor = d-box_size\n",
    "\n",
    "            for t in time_point_list: #smcs_dict.keys():\n",
    "                smcs = [(x[0]-shift_factor,x[1]-shift_factor) for x in smcs_dict[t] if (np.abs(x[0]-d)<=box_size)  and (np.abs(x[1]-d)<box_size)]\n",
    "\n",
    "                has_constraint = False\n",
    "                for x in smcs:\n",
    "                    if x[0]<box_size and x[1]>box_size:\n",
    "                        has_constraint = True\n",
    "                        break\n",
    "                if has_constraint==True:\n",
    "                    short_list.append(smcs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 50\n",
    "nreps = 2\n",
    "for si, smcs in enumerate(short_list):\n",
    "    dsb = [box_size-1,box_size]\n",
    "    L_tot = 2*box_size + base\n",
    "    \n",
    "    for rep in range(nreps):\n",
    "\n",
    "        m_samples1000, c_samples1000 = contact_map_generator_from_SMC_list_and_DSBs(smcs,dsb,L_tot,base=base,nsamples=1000)\n",
    "\n",
    "        if rep == 0 and si == 0:\n",
    "            M_samples1000_10min = m_samples1000\n",
    "            C_samples1000_10min = c_samples1000\n",
    "        else:\n",
    "            M_samples1000_10min += m_samples1000\n",
    "            C_samples1000_10min += c_samples1000\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_new_samples1000 = np.zeros((100,100))\n",
    "C_new_samples1000 = np.zeros((100,100))\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        M_new_samples1000[x//1,y//1] += M_samples1000_10min[x,y]\n",
    "        C_new_samples1000[x//1,y//1] += C_samples1000_10min[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=(M_new_samples1000/C_new_samples1000)/(M_new_samples1000_beforeDSB/C_new_samples1000_beforeDSB)\n",
    "corrected=iterative_correction_symmetric(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log2(corrected[0]),cmap='cividis',vmax=0.4,vmin=-0.4)\n",
    "plt.xlim([0,100])\n",
    "plt.ylim([0,100])\n",
    "\n",
    "plt.colorbar() \n",
    "plt.title(\"With DSB\")\n",
    "plt.savefig('Figures/'+'HiC_10min_2rep_1000samples_DividedByBeforeBSB_allTADs_vmax0.4_vmin-0.4_3rdParameterCombo_IterativeCorrected.pdf',format='pdf',bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
