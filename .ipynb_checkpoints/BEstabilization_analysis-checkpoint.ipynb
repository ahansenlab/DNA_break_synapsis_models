{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import bootstrapped.bootstrap as bts\n",
    "#import bootstrapped.stats_functions as bs_stats\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "from os import path\n",
    "\n",
    "# settings for making nice pdfs\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.sans-serif'] = \"Arial\"\n",
    "plt.rcParams['font.family'] = \"sans-serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify common string of the output folders (each folder contains results from independent runs, n>=3) \n",
    "base_folder_string = 'output_0520_tiling600_PercentBEstabilized_run'\n",
    "folders = [foldername for foldername in os.listdir('Data/') if foldername.startswith(base_folder_string)]\n",
    "\n",
    "base_stochasticity = 1 # use to convert step to time\n",
    "\n",
    "# loop through different folders\n",
    "for m in range(len(folders)):\n",
    "    data_dir = folders[m]\n",
    "    \n",
    "    stats_file = [filename for filename in os.listdir('Data/'+data_dir) if filename.startswith(\"stats_df\")]\n",
    "    \n",
    "    # parse file name\n",
    "    # separation\n",
    "    sep_list = list(set([stats_file[i].split('stats_df_sep')[1].split('_proc')[0] for i in range(len(stats_file))]))\n",
    "    sep_numerical_list = [float(a) for a in sep_list]\n",
    "    sep_list_sorted = [x for _,x in sorted(zip(sep_numerical_list,sep_list))]\n",
    "    sep_numerical_sorted = [float(a) for a in sep_list_sorted]\n",
    "    # processivity\n",
    "    proc_list = list(set([stats_file[i].split('proc')[1].split('_superportion')[0] for i in range(len(stats_file))]))\n",
    "    proc_numerical_list = [float(a) for a in proc_list]\n",
    "    proc_list_sorted = [x for _,x in sorted(zip(proc_numerical_list,proc_list))]\n",
    "    proc_numerical_sorted = [float(a) for a in proc_list_sorted]\n",
    "    # %long-lived LEFs\n",
    "    superportion_list = list(set([stats_file[i].split('superportion')[1].split('_superproc')[0] for i in range(len(stats_file))]))\n",
    "    superportion_numerical_list = [float(a) for a in superportion_list]\n",
    "    superportion_list_sorted = [x for _,x in sorted(zip(superportion_numerical_list,superportion_list))]\n",
    "    superportion_numerical_sorted = [float(a) for a in superportion_list_sorted]\n",
    "    # processivity of long-lived LEFs\n",
    "    superproc_list = list(set([stats_file[i].split('superproc')[1].split('_ctcf')[0] for i in range(len(stats_file))]))\n",
    "    superproc_numerical_list = [float(a) for a in superproc_list]\n",
    "    superproc_list_sorted = [x for _,x in sorted(zip(superproc_numerical_list,superproc_list))]\n",
    "    superproc_numerical_sorted = [float(a) for a in superproc_list_sorted]\n",
    "    # fold stabilization of LEFs at BE\n",
    "    ctcf_list = list(set([stats_file[i].split('ctcf')[1].split('_dsb')[0] for i in range(len(stats_file))]))\n",
    "    ctcf_numerical_list = [float(a) for a in ctcf_list]\n",
    "    ctcf_list_sorted = [x for _,x in sorted(zip(ctcf_numerical_list,ctcf_list))]\n",
    "    ctcf_numerical_sorted = [float(a) for a in ctcf_list_sorted]\n",
    "    # fold stabilization of LEF at DSB ends\n",
    "    dsb_list = list(set([stats_file[i].split('dsb')[1].split('_superloading')[0] for i in range(len(stats_file))]))\n",
    "    dsb_numerical_list = [float(a) for a in dsb_list]\n",
    "    dsb_list_sorted = [x for _,x in sorted(zip(dsb_numerical_list,dsb_list))]\n",
    "    dsb_numerical_sorted = [float(a) for a in dsb_list_sorted]\n",
    "    # fold increase in loading probability at DSB\n",
    "    superloading_list = list(set([stats_file[i].split('superloading')[1].split('_bs')[0] for i in range(len(stats_file))]))\n",
    "    superloading_numerical_list = [float(a) for a in superloading_list]\n",
    "    superloading_list_sorted = [x for _,x in sorted(zip(superloading_numerical_list,superloading_list))]\n",
    "    superloading_numerical_sorted = [float(a) for a in superloading_list_sorted]\n",
    "    # boundary strength\n",
    "    bs_list = list(set([stats_file[i].split('bs')[1].split('.csv')[0] for i in range(len(stats_file))]))\n",
    "    bs_numerical_list = [float(a) for a in bs_list]\n",
    "    bs_list_sorted = [x for _,x in sorted(zip(bs_numerical_list,bs_list))]\n",
    "    bs_numerical_sorted = [float(a) for a in bs_list_sorted]\n",
    "\n",
    "    if m == 0:\n",
    "        ctcf_bs_fp = np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        ctcf_bs_success =  np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        ctcf_bs_time0 =  np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        percent_LEFs_stabilized = np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        percent_TAD_with_stabilized_LEFs= np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "    \n",
    "    count = 0 \n",
    "    for i in range(len(proc_list)):\n",
    "        for j in range(len(ctcf_list)):\n",
    "            proc = proc_numerical_sorted[i]\n",
    "            par_combo = 'sep' + sep_list[0] + '_proc'+ proc_list_sorted[i] +  '_superportion' + superportion_list_sorted[0] + '_superproc' + str(int(proc*20)) + '_ctcf' + ctcf_list_sorted[j] + '_dsb' + dsb_list_sorted[0]+ '_superloading' + superloading_list_sorted[0]+ '_bs' + bs_list_sorted[0]\n",
    "\n",
    "            filename = 'Data/'+data_dir + '/stats_df_' + par_combo + '.csv'\n",
    "            if path.exists(filename):\n",
    "\n",
    "                count+=1\n",
    "\n",
    "                stats_df = pd.read_csv(filename)\n",
    "                stats_df = stats_df.drop(columns='Unnamed: 0')\n",
    "                stats_df_threshold1 = stats_df.loc[stats_df['threshold']==1]\n",
    "                sep_proc_1st_pass = stats_df_threshold1['first_passage_time'].to_numpy()\n",
    "                if len(sep_proc_1st_pass)>0:\n",
    "                    ctcf_bs_fp[m,i,j]=np.mean(sep_proc_1st_pass)*base_stochasticity/60*2\n",
    "                else:\n",
    "                    ctcf_bs_fp[m,i,j]=np.nan\n",
    "\n",
    "\n",
    "                portion_df = pd.read_csv('Data/'+data_dir + '/restrained_df_' + par_combo + '.csv')\n",
    "                portion_df = portion_df.drop(columns='Unnamed: 0')\n",
    "                portion_df_threshold1 = portion_df.loc[portion_df['threshold']==1]\n",
    "                ctcf_bs_time0[m,i,j] = portion_df_threshold1['restrained proportion time0'].to_numpy()[0] * 100\n",
    "                ctcf_bs_success[m,i,j] = portion_df_threshold1['repaired proportion'].to_numpy()[0] * 100\n",
    "                \n",
    "                \n",
    "                stabilized_df = pd.read_csv('Data/'+data_dir + '/stabilized_df_' + par_combo + '.csv')\n",
    "                stabilized_df = stabilized_df.drop(columns='Unnamed: 0')\n",
    "                percent_LEFs_stabilized[m,i,j] = stabilized_df ['percent LEF stabilized by BE'].to_numpy()[0] \n",
    "                percent_TAD_with_stabilized_LEFs[m,i,j] = stabilized_df ['percent TADs with stabilized LEF'].to_numpy()[0]\n",
    "\n",
    "# Theory prediction from Mathematica Notebook BEstabilization_20211004.nb, Prob\n",
    "theory = np.asarray([[0.0484416, 0.0766689, 0.104387, 0.131435, 0.157444, 0.182136, \\\n",
    "0.205379, 0.227153, 0.247505, 0.26652, 0.284297, 0.30094, 0.316549, \\\n",
    "0.331218, 0.345032, 0.358068, 0.370395, 0.382075, 0.393162, 0.403707, \\\n",
    "0.413751, 0.423335, 0.432493, 0.441258, 0.449656, 0.457713, 0.465454, \\\n",
    "0.472897, 0.480063, 0.486969, 0.493631],[0.113293, 0.166839, 0.214683, 0.257562, 0.29593, 0.330265, 0.361058, \\\n",
    "0.38877, 0.413809, 0.436534, 0.457245, 0.476202, 0.493621, 0.509688, \\\n",
    "0.524558, 0.538367, 0.551228, 0.56324, 0.574489, 0.585048, 0.594984, \\\n",
    "0.604352, 0.613202, 0.621578, 0.629521, 0.637063, 0.644238, 0.651072, \\\n",
    "0.657591, 0.663817, 0.669771],[0.204531, 0.280211, 0.341936, 0.393317, 0.436676, 0.473701, 0.505662, \\\n",
    "0.533524, 0.55803, 0.579758, 0.599162, 0.616603, 0.632372, 0.646705, \\\n",
    "0.659795, 0.671802, 0.682859, 0.69308, 0.702558, 0.711374, 0.719599, \\\n",
    "0.727292, 0.734506, 0.741284, 0.747668, 0.753692, 0.759387, 0.764781, \\\n",
    "0.769897, 0.774757, 0.779382]])*100\n",
    "\n",
    "slist = np.asarray([1., 1.5, 2., 2.5, 3., 3.5, 4., 4.5, 5., 5.5, 6., 6.5, 7., 7.5, 8., \\\n",
    "8.5, 9., 9.5, 10., 10.5, 11., 11.5, 12., 12.5, 13., 13.5, 14., 14.5, \\\n",
    "15., 15.5, 16.])\n",
    "    \n",
    "colors = ['aqua','slateblue','violet','deeppink','mediumorchid']\n",
    "matplotlib.rcParams.update({'font.size': 22})       \n",
    "fig, axs = plt.subplots(2,1,figsize=(8, 12))\n",
    "    \n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[0].errorbar(ctcf_numerical_sorted, np.transpose(np.mean(ctcf_bs_success,axis=0)[i,:]),yerr =stats.sem(ctcf_bs_success,axis=0)[i,:],fmt='s',markersize = 8,ecolor= colors[i],color= colors[i],capsize=10,linewidth=3)\n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[0].plot(slist,theory[i],color= colors[i],linewidth=3,linestyle='dashed')\n",
    "    \n",
    "axs[0].set_ylim(0,100)    \n",
    "axs[0].set_ylabel('Synapsis efficiency(%)')\n",
    "axs[0].set_xlabel('BE stabilization factor')\n",
    "axs[0].set_xticks(ctcf_numerical_sorted[0:])\n",
    "axs[0].tick_params(direction='out', length=8, width=2)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axs[0].spines[axis].set_linewidth(1.5)\n",
    "    \n",
    "# Hide the right and top spines\n",
    "axs[0].spines['right'].set_visible(False)\n",
    "axs[0].spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axs[0].yaxis.set_ticks_position('left')\n",
    "axs[0].xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[1].errorbar(ctcf_numerical_sorted , np.transpose(np.mean(ctcf_bs_fp,axis=0)[i,:]),yerr =stats.sem(ctcf_bs_fp,axis=0)[i,:],fmt='s',markersize = 8,ecolor= colors[i],color= colors[i],capsize=10,linewidth=3)\n",
    "\n",
    "axs[1].set_ylabel('Mean synapsis time (min)')\n",
    "axs[1].set_xlabel('BE stabilization factor')\n",
    "axs[1].tick_params(direction='out', length=8, width=2)\n",
    "axs[1].set_xticks(ctcf_numerical_sorted[0:])\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axs[1].spines[axis].set_linewidth(1.5)\n",
    "    \n",
    "legend = ['processivity='+proc for proc in proc_list_sorted]\n",
    "lgd = axs[1].legend(legend,loc='upper center', bbox_to_anchor=(0.5, -0.2),\n",
    "          fancybox=True, shadow=True, ncol=1)    \n",
    "    \n",
    "# Hide the right and top spines\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "axs[1].spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axs[1].yaxis.set_ticks_position('left')\n",
    "axs[1].xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.savefig('Figures/'+'BE_stabilization.pdf',format='pdf',bbox_extra_artists=(lgd,),bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder_string = 'output_0520_with residence_10 Mb apart_tiling600_2populationLEFs_GapMethod_PercentBEstabilized_run'\n",
    "folders = [foldername for foldername in os.listdir('Data/') if foldername.startswith(base_folder_string)]\n",
    "\n",
    "base_stochasticity = 1 # use to convert step to time\n",
    "\n",
    "for m in range(len(folders)):\n",
    "    data_dir = folders[m]\n",
    "    print(data_dir)\n",
    "    stats_file = [filename for filename in os.listdir('Data/'+data_dir) if filename.startswith(\"stats_df\")]\n",
    "\n",
    "    sep_list = list(set([stats_file[i].split('stats_df_sep')[1].split('_proc')[0] for i in range(len(stats_file))]))\n",
    "    sep_numerical_list = [float(a) for a in sep_list]\n",
    "    sep_list_sorted = [x for _,x in sorted(zip(sep_numerical_list,sep_list))]\n",
    "    sep_numerical_sorted = [float(a) for a in sep_list_sorted]\n",
    "    proc_list = list(set([stats_file[i].split('proc')[1].split('_superportion')[0] for i in range(len(stats_file))]))\n",
    "    proc_numerical_list = [float(a) for a in proc_list]\n",
    "    proc_list_sorted = [x for _,x in sorted(zip(proc_numerical_list,proc_list))]\n",
    "    proc_numerical_sorted = [float(a) for a in proc_list_sorted]\n",
    "    superportion_list = list(set([stats_file[i].split('superportion')[1].split('_superproc')[0] for i in range(len(stats_file))]))\n",
    "    superportion_numerical_list = [float(a) for a in superportion_list]\n",
    "    superportion_list_sorted = [x for _,x in sorted(zip(superportion_numerical_list,superportion_list))]\n",
    "    superportion_numerical_sorted = [float(a) for a in superportion_list_sorted]\n",
    "    superproc_list = list(set([stats_file[i].split('superproc')[1].split('_ctcf')[0] for i in range(len(stats_file))]))\n",
    "    superproc_numerical_list = [float(a) for a in superproc_list]\n",
    "    superproc_list_sorted = [x for _,x in sorted(zip(superproc_numerical_list,superproc_list))]\n",
    "    superproc_numerical_sorted = [float(a) for a in superproc_list_sorted]\n",
    "    ctcf_list = list(set([stats_file[i].split('ctcf')[1].split('_dsb')[0] for i in range(len(stats_file))]))\n",
    "    ctcf_numerical_list = [float(a) for a in ctcf_list]\n",
    "    ctcf_list_sorted = [x for _,x in sorted(zip(ctcf_numerical_list,ctcf_list))]\n",
    "    ctcf_numerical_sorted = [float(a) for a in ctcf_list_sorted]\n",
    "    dsb_list = list(set([stats_file[i].split('dsb')[1].split('_superloading')[0] for i in range(len(stats_file))]))\n",
    "    dsb_numerical_list = [float(a) for a in dsb_list]\n",
    "    dsb_list_sorted = [x for _,x in sorted(zip(dsb_numerical_list,dsb_list))]\n",
    "    dsb_numerical_sorted = [float(a) for a in dsb_list_sorted ]\n",
    "    superloading_list = list(set([stats_file[i].split('superloading')[1].split('_bs')[0] for i in range(len(stats_file))]))\n",
    "    superloading_numerical_list = [float(a) for a in superloading_list]\n",
    "    superloading_list_sorted = [x for _,x in sorted(zip(superloading_numerical_list,superloading_list))]\n",
    "    superloading_numerical_sorted = [float(a) for a in superloading_list_sorted]\n",
    "    bs_list = list(set([stats_file[i].split('bs')[1].split('.csv')[0] for i in range(len(stats_file))]))\n",
    "    bs_numerical_list = [float(a) for a in bs_list]\n",
    "    bs_list_sorted = [x for _,x in sorted(zip(bs_numerical_list,bs_list))]\n",
    "    bs_numerical_sorted = [float(a) for a in bs_list_sorted]\n",
    "\n",
    "    if m == 0:\n",
    "        ctcf_bs_fp = np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        ctcf_bs_success =  np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        ctcf_bs_capture =  np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        ctcf_bs_time0 =  np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        percent_LEFs_stabilized = np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        percent_TAD_with_stabilized_LEFs= np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "    \n",
    "    count = 0 \n",
    "    for i in range(len(proc_list)):\n",
    "        for j in range(len(ctcf_list)):\n",
    "            proc = proc_numerical_sorted[i]\n",
    "            par_combo = 'sep' + sep_list[0] + '_proc'+ proc_list_sorted[i] +  '_superportion' + superportion_list_sorted[0] + '_superproc' + str(int(proc*20)) + '_ctcf' + ctcf_list_sorted[j] + '_dsb' + dsb_list_sorted[0]+ '_superloading' + superloading_list_sorted[0]+ '_bs' + bs_list_sorted[0]\n",
    "\n",
    "            filename = 'Data/'+data_dir + '/stats_df_' + par_combo + '.csv'\n",
    "            if path.exists(filename):\n",
    "\n",
    "                count+=1\n",
    "\n",
    "                stats_df = pd.read_csv(filename)\n",
    "                stats_df = stats_df.drop(columns='Unnamed: 0')\n",
    "                stats_df_threshold1 = stats_df.loc[stats_df['threshold']==1]\n",
    "                sep_proc_1st_pass = stats_df_threshold1['first_passage_time'].to_numpy()\n",
    "                if len(sep_proc_1st_pass)>0:\n",
    "                    ctcf_bs_fp[m,i,j]=np.mean(sep_proc_1st_pass)*base_stochasticity/60*2\n",
    "                else:\n",
    "                    ctcf_bs_fp[m,i,j]=np.nan\n",
    "\n",
    "\n",
    "                portion_df = pd.read_csv('Data/'+data_dir + '/restrained_df_' + par_combo + '.csv')\n",
    "                portion_df = portion_df.drop(columns='Unnamed: 0')\n",
    "                portion_df_threshold1 = portion_df.loc[portion_df['threshold']==1]\n",
    "                ctcf_bs_time0[m,i,j] = portion_df_threshold1['restrained proportion time0'].to_numpy()[0] * 100\n",
    "                ctcf_bs_success[m,i,j] = portion_df_threshold1['repaired proportion'].to_numpy()[0] * 100\n",
    "                \n",
    "                ctcf_bs_capture[m,i,j] = ctcf_bs_success[m,i,j]/ctcf_bs_time0[m,i,j]\n",
    "                \n",
    "                stabilized_df = pd.read_csv('Data/'+data_dir + '/stabilized_df_' + par_combo + '.csv')\n",
    "                stabilized_df = stabilized_df.drop(columns='Unnamed: 0')\n",
    "                percent_LEFs_stabilized[m,i,j] = stabilized_df ['percent LEF stabilized by BE'].to_numpy()[0] \n",
    "                percent_TAD_with_stabilized_LEFs[m,i,j] = stabilized_df ['percent TADs with stabilized LEF'].to_numpy()[0]\n",
    "\n",
    "# Theory prediction from Mathematica Notebook BEstabilization_20211004.nb, Probconstrained\n",
    "theory = np.asarray([[0.707582, 0.723565, 0.743412, 0.763302, 0.781692, 0.79811, 0.812548, \\\n",
    "0.825179, 0.836228, 0.845918, 0.854449, 0.861996, 0.868704, 0.874695, \\\n",
    "0.880073, 0.884923, 0.889314, 0.893309, 0.896955, 0.900297, 0.90337, \\\n",
    "0.906204, 0.908828, 0.911262, 0.913527, 0.915641, 0.917617, 0.919469, \\\n",
    "0.921208, 0.922845, 0.924389],[0.822697, 0.836857, 0.851558, 0.864668, 0.875844, 0.885264, 0.893215, \\\n",
    "0.899969, 0.905754, 0.910752, 0.915108, 0.918934, 0.922321, 0.92534, \\\n",
    "0.928048, 0.93049, 0.932706, 0.934725, 0.936573, 0.938272, 0.93984, \\\n",
    "0.941292, 0.942641, 0.943898, 0.945072, 0.946172, 0.947206, 0.948179, \\\n",
    "0.949096, 0.949963, 0.950785],[0.892005, 0.901986, 0.911057, 0.918585, 0.924746, 0.929821, 0.934052, \\\n",
    "0.937627, 0.940686, 0.943334, 0.94565, 0.947695, 0.949516, 0.951148, \\\n",
    "0.952623, 0.953961, 0.955184, 0.956306, 0.95734, 0.958297, 0.959185, \\\n",
    "0.960014, 0.960788, 0.961514, 0.962196, 0.962839, 0.963446, 0.964021, \\\n",
    "0.964566, 0.965084, 0.965577]])*100\n",
    "\n",
    "# Theory prediction from Mathematica Notebook BEstabilization_20211004.nb, blist\n",
    "theory2 = np.asarray([[0.166537, 0.209877, 0.241864, 0.266608, 0.286403, 0.302647, 0.316246, \\\n",
    "0.327814, 0.337787, 0.346481, 0.354133, 0.360923, 0.366992, 0.372452, \\\n",
    "0.37739, 0.38188, 0.385981, 0.389742, 0.393204, 0.396402, 0.399365, \\\n",
    "0.402119, 0.404685, 0.407083, 0.409327, 0.411433, 0.413413, 0.415279, \\\n",
    "0.417039, 0.418703, 0.420278],[0.241864, 0.286403, 0.316246, 0.337787, 0.354133, 0.366992, 0.37739, \\\n",
    "0.385981, 0.393204, 0.399365, 0.404685, 0.409327, 0.413413, 0.417039, \\\n",
    "0.420278, 0.42319, 0.425822, 0.428214, 0.430396, 0.432395, 0.434233, \\\n",
    "0.43593, 0.4375, 0.438958, 0.440315, 0.441582, 0.442767, 0.443877, \\\n",
    "0.44492, 0.445902, 0.446828],[0.316246, 0.354133, 0.37739, 0.393204, 0.404685, 0.413413, 0.420278, \\\n",
    "0.425822, 0.430396, 0.434233, 0.4375, 0.440315, 0.442767, 0.44492, \\\n",
    "0.446828, 0.44853, 0.450057, 0.451435, 0.452685, 0.453824, 0.454867, \\\n",
    "0.455824, 0.456706, 0.457522, 0.458279, 0.458983, 0.459639, 0.460252, \\\n",
    "0.460826, 0.461365, 0.461872]])*100\n",
    "\n",
    "slist = np.asarray([1., 1.5, 2., 2.5, 3., 3.5, 4., 4.5, 5., 5.5, 6., 6.5, 7., 7.5, 8., \\\n",
    "8.5, 9., 9.5, 10., 10.5, 11., 11.5, 12., 12.5, 13., 13.5, 14., 14.5, \\\n",
    "15., 15.5, 16.])\n",
    "    \n",
    "colors = ['aqua','slateblue','violet','deeppink','mediumorchid']\n",
    "matplotlib.rcParams.update({'font.size': 22})       \n",
    "fig, axs = plt.subplots(2,1,figsize=(8, 12))\n",
    "    \n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[0].errorbar(ctcf_numerical_sorted, np.transpose(np.mean(ctcf_bs_time0,axis=0)[i,:]),yerr =stats.sem(ctcf_bs_time0,axis=0)[i,:],fmt='s',markersize = 8,ecolor= colors[i],color= colors[i],capsize=10,linewidth=3)\n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[0].plot(slist,theory[i],color= colors[i],linewidth=3,linestyle='dashed')\n",
    "    \n",
    "axs[0].set_ylim(0,100)    \n",
    "axs[0].set_ylabel('% DSB constrained')\n",
    "axs[0].set_xlabel('BE stabilization factor')\n",
    "axs[0].set_xticks(ctcf_numerical_sorted[0:])\n",
    "axs[0].tick_params(direction='out', length=8, width=2)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axs[0].spines[axis].set_linewidth(1.5)\n",
    "    \n",
    "# Hide the right and top spines\n",
    "axs[0].spines['right'].set_visible(False)\n",
    "axs[0].spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axs[0].yaxis.set_ticks_position('left')\n",
    "axs[0].xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[1].errorbar(ctcf_numerical_sorted, np.transpose(np.mean( percent_LEFs_stabilized,axis=0)[i,:]),yerr =stats.sem( percent_LEFs_stabilized,axis=0)[i,:],fmt='s',markersize = 8,ecolor= colors[i],color= colors[i],capsize=10,linewidth=3)\n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[1].plot(slist,theory2[i],color= colors[i],linewidth=3,linestyle='dashed')\n",
    "    \n",
    "axs[1].set_ylim(0,100)    \n",
    "axs[1].set_ylabel('% LEFs stabilized by BE')\n",
    "axs[1].set_xlabel('BE stabilization factor')\n",
    "axs[1].set_xticks(ctcf_numerical_sorted[0:])\n",
    "axs[1].tick_params(direction='out', length=8, width=2)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axs[1].spines[axis].set_linewidth(1.5)\n",
    "    \n",
    "# Hide the right and top spines\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "axs[1].spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axs[1].yaxis.set_ticks_position('left')\n",
    "axs[1].xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "\n",
    "plt.savefig('Figures/'+'BE_stabilization_Pconstrained_percentLEFstabilized.pdf',format='pdf',bbox_extra_artists=(lgd,),bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder_string = 'output_0520_with residence_10 Mb apart_tiling600_2populationLEFs_GapMethod_PercentBEstabilized_run'\n",
    "folders = [foldername for foldername in os.listdir('Data/') if foldername.startswith(base_folder_string)]\n",
    "\n",
    "base_stochasticity = 1 # use to convert step to time\n",
    "\n",
    "for m in range(len(folders)):\n",
    "    data_dir = folders[m]\n",
    "    print(data_dir)\n",
    "    stats_file = [filename for filename in os.listdir('Data/'+data_dir) if filename.startswith(\"stats_df\")]\n",
    "\n",
    "    sep_list = list(set([stats_file[i].split('stats_df_sep')[1].split('_proc')[0] for i in range(len(stats_file))]))\n",
    "    sep_numerical_list = [float(a) for a in sep_list]\n",
    "    sep_list_sorted = [x for _,x in sorted(zip(sep_numerical_list,sep_list))]\n",
    "    sep_numerical_sorted = [float(a) for a in sep_list_sorted]\n",
    "    proc_list = list(set([stats_file[i].split('proc')[1].split('_superportion')[0] for i in range(len(stats_file))]))\n",
    "    proc_numerical_list = [float(a) for a in proc_list]\n",
    "    proc_list_sorted = [x for _,x in sorted(zip(proc_numerical_list,proc_list))]\n",
    "    proc_numerical_sorted = [float(a) for a in proc_list_sorted]\n",
    "    superportion_list = list(set([stats_file[i].split('superportion')[1].split('_superproc')[0] for i in range(len(stats_file))]))\n",
    "    superportion_numerical_list = [float(a) for a in superportion_list]\n",
    "    superportion_list_sorted = [x for _,x in sorted(zip(superportion_numerical_list,superportion_list))]\n",
    "    superportion_numerical_sorted = [float(a) for a in superportion_list_sorted]\n",
    "    superproc_list = list(set([stats_file[i].split('superproc')[1].split('_ctcf')[0] for i in range(len(stats_file))]))\n",
    "    superproc_numerical_list = [float(a) for a in superproc_list]\n",
    "    superproc_list_sorted = [x for _,x in sorted(zip(superproc_numerical_list,superproc_list))]\n",
    "    superproc_numerical_sorted = [float(a) for a in superproc_list_sorted]\n",
    "    ctcf_list = list(set([stats_file[i].split('ctcf')[1].split('_dsb')[0] for i in range(len(stats_file))]))\n",
    "    ctcf_numerical_list = [float(a) for a in ctcf_list]\n",
    "    ctcf_list_sorted = [x for _,x in sorted(zip(ctcf_numerical_list,ctcf_list))]\n",
    "    ctcf_numerical_sorted = [float(a) for a in ctcf_list_sorted]\n",
    "    dsb_list = list(set([stats_file[i].split('dsb')[1].split('_superloading')[0] for i in range(len(stats_file))]))\n",
    "    dsb_numerical_list = [float(a) for a in dsb_list]\n",
    "    dsb_list_sorted = [x for _,x in sorted(zip(dsb_numerical_list,dsb_list))]\n",
    "    dsb_numerical_sorted = [float(a) for a in dsb_list_sorted ]\n",
    "    superloading_list = list(set([stats_file[i].split('superloading')[1].split('_bs')[0] for i in range(len(stats_file))]))\n",
    "    superloading_numerical_list = [float(a) for a in superloading_list]\n",
    "    superloading_list_sorted = [x for _,x in sorted(zip(superloading_numerical_list,superloading_list))]\n",
    "    superloading_numerical_sorted = [float(a) for a in superloading_list_sorted]\n",
    "    bs_list = list(set([stats_file[i].split('bs')[1].split('.csv')[0] for i in range(len(stats_file))]))\n",
    "    bs_numerical_list = [float(a) for a in bs_list]\n",
    "    bs_list_sorted = [x for _,x in sorted(zip(bs_numerical_list,bs_list))]\n",
    "    bs_numerical_sorted = [float(a) for a in bs_list_sorted]\n",
    "\n",
    "    if m == 0:\n",
    "        ctcf_bs_fp = np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        ctcf_bs_success =  np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        ctcf_bs_capture =  np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        ctcf_bs_realtime =  np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        ctcf_bs_time0 =  np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        percent_LEFs_stabilized = np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "        percent_TAD_with_stabilized_LEFs= np.zeros((len(folders),len(proc_list),len(ctcf_list)))\n",
    "    \n",
    "    count = 0 \n",
    "    for i in range(len(proc_list)):\n",
    "        for j in range(len(ctcf_list)):\n",
    "            proc = proc_numerical_sorted[i]\n",
    "            par_combo = 'sep' + sep_list[0] + '_proc'+ proc_list_sorted[i] +  '_superportion' + superportion_list_sorted[0] + '_superproc' + str(int(proc*20)) + '_ctcf' + ctcf_list_sorted[j] + '_dsb' + dsb_list_sorted[0]+ '_superloading' + superloading_list_sorted[0]+ '_bs' + bs_list_sorted[0]\n",
    "\n",
    "            filename = 'Data/'+data_dir + '/stats_df_' + par_combo + '.csv'\n",
    "            if path.exists(filename):\n",
    "\n",
    "                count+=1\n",
    "\n",
    "                stats_df = pd.read_csv(filename)\n",
    "                stats_df = stats_df.drop(columns='Unnamed: 0')\n",
    "                stats_df_threshold1 = stats_df.loc[stats_df['threshold']==1]\n",
    "                sep_proc_1st_pass = stats_df_threshold1['first_passage_time'].to_numpy()\n",
    "                if len(sep_proc_1st_pass)>0:\n",
    "                    ctcf_bs_fp[m,i,j]=np.mean(sep_proc_1st_pass)*base_stochasticity/60*2\n",
    "                else:\n",
    "                    ctcf_bs_fp[m,i,j]=np.nan\n",
    "\n",
    "\n",
    "                portion_df = pd.read_csv('Data/'+data_dir + '/restrained_df_' + par_combo + '.csv')\n",
    "                portion_df = portion_df.drop(columns='Unnamed: 0')\n",
    "                portion_df_threshold1 = portion_df.loc[portion_df['threshold']==1]\n",
    "                ctcf_bs_time0[m,i,j] = portion_df_threshold1['restrained proportion time0'].to_numpy()[0] * 100\n",
    "                ctcf_bs_realtime[m,i,j] = portion_df_threshold1['restrained proportion realtime'].to_numpy()[0] * 100\n",
    "                ctcf_bs_success[m,i,j] = portion_df_threshold1['repaired proportion'].to_numpy()[0] * 100\n",
    "                \n",
    "                ctcf_bs_capture[m,i,j] = ctcf_bs_success[m,i,j]/ctcf_bs_time0[m,i,j]\n",
    "                \n",
    "                stabilized_df = pd.read_csv('Data/'+data_dir + '/stabilized_df_' + par_combo + '.csv')\n",
    "                stabilized_df = stabilized_df.drop(columns='Unnamed: 0')\n",
    "                percent_LEFs_stabilized[m,i,j] = stabilized_df ['percent LEF stabilized by BE'].to_numpy()[0] \n",
    "                percent_TAD_with_stabilized_LEFs[m,i,j] = stabilized_df ['percent TADs with stabilized LEF'].to_numpy()[0]\n",
    "\n",
    "# Theory prediction from Mathematica Notebook BEstabilization_20211004.nb, Probconstrained\n",
    "theory = np.asarray([[0.707582, 0.723565, 0.743412, 0.763302, 0.781692, 0.79811, 0.812548, \\\n",
    "0.825179, 0.836228, 0.845918, 0.854449, 0.861996, 0.868704, 0.874695, \\\n",
    "0.880073, 0.884923, 0.889314, 0.893309, 0.896955, 0.900297, 0.90337, \\\n",
    "0.906204, 0.908828, 0.911262, 0.913527, 0.915641, 0.917617, 0.919469, \\\n",
    "0.921208, 0.922845, 0.924389],[0.822697, 0.836857, 0.851558, 0.864668, 0.875844, 0.885264, 0.893215, \\\n",
    "0.899969, 0.905754, 0.910752, 0.915108, 0.918934, 0.922321, 0.92534, \\\n",
    "0.928048, 0.93049, 0.932706, 0.934725, 0.936573, 0.938272, 0.93984, \\\n",
    "0.941292, 0.942641, 0.943898, 0.945072, 0.946172, 0.947206, 0.948179, \\\n",
    "0.949096, 0.949963, 0.950785],[0.892005, 0.901986, 0.911057, 0.918585, 0.924746, 0.929821, 0.934052, \\\n",
    "0.937627, 0.940686, 0.943334, 0.94565, 0.947695, 0.949516, 0.951148, \\\n",
    "0.952623, 0.953961, 0.955184, 0.956306, 0.95734, 0.958297, 0.959185, \\\n",
    "0.960014, 0.960788, 0.961514, 0.962196, 0.962839, 0.963446, 0.964021, \\\n",
    "0.964566, 0.965084, 0.965577]])*100\n",
    "\n",
    "# Theory prediction from Mathematica Notebook BEstabilization_20211004.nb, Pstabilizedlist\n",
    "theory2 = np.asarray([[0.528593, 0.64, 0.714249, 0.76673, 0.805441, 0.83494, 0.858007, \\\n",
    "0.876427, 0.891395, 0.903739, 0.914051, 0.922759, 0.930185, 0.936573, \\\n",
    "0.94211, 0.946943, 0.951187, 0.954935, 0.958263, 0.961232, 0.963891, \\\n",
    "0.966284, 0.968444, 0.970402, 0.972181, 0.973804, 0.975287, 0.976648, \\\n",
    "0.977898, 0.97905, 0.980113],[0.714249, 0.805441, 0.858007, 0.891395, 0.914051, 0.930185, 0.94211, \\\n",
    "0.951187, 0.958263, 0.963891, 0.968444, 0.972181, 0.975287, 0.977898, \\\n",
    "0.980113, 0.98201, 0.983646, 0.985068, 0.986312, 0.987406, 0.988373, \\\n",
    "0.989233, 0.99, 0.990688, 0.991307, 0.991866, 0.992373, 0.992834, \\\n",
    "0.993254, 0.993639, 0.993991],[0.858007, 0.914051, 0.94211, 0.958263, 0.968444, 0.975287, 0.980113, \\\n",
    "0.983646, 0.986312, 0.988373, 0.99, 0.991307, 0.992373, 0.993254, \\\n",
    "0.993991, 0.994613, 0.995143, 0.995598, 0.995992, 0.996336, 0.996637, \\\n",
    "0.996902, 0.997137, 0.997347, 0.997534, 0.997702, 0.997853, 0.99799, \\\n",
    "0.998114, 0.998227, 0.998331]])*100\n",
    "\n",
    "slist = np.asarray([1., 1.5, 2., 2.5, 3., 3.5, 4., 4.5, 5., 5.5, 6., 6.5, 7., 7.5, 8., \\\n",
    "8.5, 9., 9.5, 10., 10.5, 11., 11.5, 12., 12.5, 13., 13.5, 14., 14.5, \\\n",
    "15., 15.5, 16])\n",
    "    \n",
    "colors = ['aqua','slateblue','violet','deeppink','mediumorchid']\n",
    "matplotlib.rcParams.update({'font.size': 22})       \n",
    "fig, axs = plt.subplots(2,1,figsize=(8, 12))\n",
    "    \n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[0].errorbar(ctcf_numerical_sorted, np.transpose(np.mean(ctcf_bs_time0,axis=0)[i,:]),yerr =stats.sem(ctcf_bs_time0,axis=0)[i,:],fmt='s',markersize = 8,ecolor= colors[i],color= colors[i],capsize=10,linewidth=3)\n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[0].plot(slist,theory[i],color= colors[i],linewidth=3,linestyle='dashed')\n",
    "    \n",
    "axs[0].set_ylim(0,100)    \n",
    "axs[0].set_ylabel('% DSB constrained')\n",
    "axs[0].set_xlabel('BE stabilization factor')\n",
    "axs[0].set_xticks(ctcf_numerical_sorted[0:])\n",
    "axs[0].tick_params(direction='out', length=8, width=2)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axs[0].spines[axis].set_linewidth(1.5)\n",
    "    \n",
    "# Hide the right and top spines\n",
    "axs[0].spines['right'].set_visible(False)\n",
    "axs[0].spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axs[0].yaxis.set_ticks_position('left')\n",
    "axs[0].xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[1].errorbar(ctcf_numerical_sorted, np.transpose(np.mean(percent_TAD_with_stabilized_LEFs,axis=0)[i,:]),yerr =stats.sem(percent_TAD_with_stabilized_LEFs,axis=0)[i,:],fmt='s',markersize = 8,ecolor= colors[i],color= colors[i],capsize=10,linewidth=3)\n",
    "for i in range(len(proc_list_sorted)):\n",
    "    axs[1].plot(slist,theory2[i],color= colors[i],linewidth=3,linestyle='dashed')\n",
    "    \n",
    "axs[1].set_ylim(0,100)    \n",
    "axs[1].set_ylabel('% TADs stabilized by BE')\n",
    "axs[1].set_xlabel('BE stabilization factor')\n",
    "axs[1].set_xticks(ctcf_numerical_sorted[0:])\n",
    "axs[1].tick_params(direction='out', length=8, width=2)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    axs[1].spines[axis].set_linewidth(1.5)\n",
    "    \n",
    "# Hide the right and top spines\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "axs[1].spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axs[1].yaxis.set_ticks_position('left')\n",
    "axs[1].xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "\n",
    "plt.savefig('Figures/'+'BE_stabilization_%TADstabilized.pdf',format='pdf',bbox_extra_artists=(lgd,),bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
