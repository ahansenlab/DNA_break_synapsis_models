{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import csv\n",
    "# for parallel processing\n",
    "from multiprocess import Pool\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "\n",
    "# import plotting functions\n",
    "from harvey_plotting_v53 import *\n",
    "\n",
    "# import loop extrusion codes\n",
    "import pyximport\n",
    "pyximport.install(setup_args={'include_dirs':np.get_include()})\n",
    "from loop_extrusion_twoLEFpopulations_CollidingSuperExtruder_SuperLoading_v15 import LEFTranslocatorDirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output folder \n",
    "output_folder = 'output_1013_test_run1'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "tiling_factor = 600 # number of TAD arrays repeated\n",
    "\n",
    "# set up boundary elements\n",
    "boundary_coordinates = [0, 200,201, 601,602, 802,803, 1603,1604, 1804,1805, 2205,2206, 2406,2407, 3607] # coordinates of boundary elements\n",
    "TAD_array_size =  boundary_coordinates[-1] + 1 # the size of the big TAD in kb\n",
    "chrom_size = TAD_array_size*tiling_factor # the total size of the chromosome in kb\n",
    "boundary_coordinates_o = boundary_coordinates # coordinates of boundary elements within the first TAD array\n",
    "\n",
    "# obtain the coordinates of all boundary elements and the double strand break sites on the chromosome\n",
    "for j in range(tiling_factor-1):\n",
    "    k = TAD_array_size*(j+1)\n",
    "    res = [x + k for x in boundary_coordinates_o] \n",
    "    boundary_coordinates = boundary_coordinates + res\n",
    "    \n",
    "# randomly determine the coordinate of the DSB in the first TAD\n",
    "random_pick_0 = int(np.random.random()*(boundary_coordinates_o[1]-boundary_coordinates_o[0]-2)+boundary_coordinates_o[0]+1)\n",
    "if random_pick_0+1 == boundary_coordinates[1]:\n",
    "    DSB_coordinates = [random_pick_0-1, random_pick_0]\n",
    "else:\n",
    "    DSB_coordinates = [random_pick_0, random_pick_0+1]\n",
    "\n",
    "# counters for the number of subTADs with a double strand break\n",
    "tad_200 = 1 \n",
    "tad_400 = 0\n",
    "tad_800 = 0\n",
    "tad_1200 = 0\n",
    "tad_count = np.asarray([1,0,0,0]) # counter for TAD of each size containing DSB\n",
    "tad_size = np.asarray([200, 400, 800, 1200]) \n",
    "\n",
    "\n",
    "dist_between_break = 10000 #kb distances between two DSB\n",
    "\n",
    "DSB_dist_to_CTCF = [min(DSB_coordinates[0]-boundary_coordinates[0],boundary_coordinates[1]-DSB_coordinates[0])] \n",
    "\n",
    "DSB_TAD_array_size = [200]\n",
    "within_tile = True\n",
    "while within_tile:\n",
    "    # skip dist_between_break \n",
    "    next_break = DSB_coordinates[-1] + dist_between_break\n",
    "    # preventing the next DSB occurring at a boundary element\n",
    "    if np.count_nonzero(next_break - np.asarray(boundary_coordinates))<len(boundary_coordinates):\n",
    "        next_break += 2\n",
    "    # determine the TAD the next DSB occurs in\n",
    "    test = np.asarray(boundary_coordinates) - next_break\n",
    "    boundray_index = np.argmax(test>0) # the first BE coordinates to the right of the DSB\n",
    "    # randomize the coordinate of the DSB within the TAD (so that the distance between DSB and BE is randomized)\n",
    "    random_pick = int(np.random.random()*(boundary_coordinates[boundray_index]-boundary_coordinates[boundray_index-1]-2)+boundary_coordinates[boundray_index-1]+1)\n",
    "    if random_pick+1 == boundary_coordinates[boundray_index]:\n",
    "        DSB_coordinates += [random_pick-1, random_pick]\n",
    "    else:\n",
    "        DSB_coordinates += [random_pick, random_pick+1]\n",
    "    tad_size_index = np.argwhere(tad_size==boundary_coordinates[boundray_index]-boundary_coordinates[boundray_index-1])[0][0]\n",
    "    tad_count[tad_size_index]+=1\n",
    "    DSB_TAD_array_size.append(tad_size[tad_size_index])\n",
    "    if DSB_coordinates[-1] + dist_between_break> chrom_size-1:\n",
    "        within_tile = False\n",
    "\n",
    "\n",
    "DSB_TAD_array_size = np.asarray(DSB_TAD_array_size)\n",
    "        \n",
    "LogFileName = output_folder+\"/log.txt\"\n",
    "\n",
    "o = open(LogFileName, \"w\") \n",
    "o.close()\n",
    "\n",
    "with open(LogFileName, \"a\") as f:\n",
    "    f.write('Tiling factor: \\n')\n",
    "    f.write(str(tiling_factor)+'\\n')\n",
    "    for i in range(len(tad_size)):\n",
    "        f.write('number of breaks within a '+str(tad_size[i])+'kb TADs: \\n')\n",
    "        f.write(str(tad_count[i])+'\\n')\n",
    "\n",
    "file = output_folder+'/DSB_boundary_coordinates.npy' \n",
    "\n",
    "# saving DSB coordinates and boundary coordinates to robustness \n",
    "if not os.path.exists(file):\n",
    "    with open(file, 'wb') as g:\n",
    "        np.save(g, np.asarray(DSB_coordinates))\n",
    "        np.save(g, np.asarray(boundary_coordinates))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the parameter sweep & simulation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define simulation parameters\n",
    "# list of (separation,processivity) tuple \n",
    "sep_proc_list = []\n",
    "sep_list = [125]\n",
    "proc_list = [250]\n",
    "for sep in sep_list:\n",
    "    for proc in proc_list:\n",
    "        sep_proc_list.append((sep,proc))\n",
    "        \n",
    "proc_ratio = 20 # the ratio of long-lived LEF processivity over normal LEF processivity  \n",
    "BE_stabilization_factor_list =  [16] # the fold stabilization of LEF at BE\n",
    "DSB_stabilization_factor_list = [4] # the fold stabilization of LEF at DSB ends\n",
    "boundary_strength_list = [0.5] # the probability of LEF stalled by an boundary element\n",
    "longlived_fraction_list = [0.2] # percentage of long-lived LEFs in the total LEF polulation\n",
    "targetedloading_factor_list = [1000] # fold increase of loading probability at the DSB ends\n",
    "\n",
    "alpha_list = [1, 3, 5]   # threshold distance: half of the unfilled gap size (in kb) for calling synapsis\n",
    "\n",
    "# other input parameters\n",
    "LEF_step_probability = 1 # the probability LEF taking a step\n",
    "    \n",
    "# maximum number of steps post DSB to stop simulation\n",
    "step_count_limit = 40000\n",
    "\n",
    "# whether to take snapshots of the synapsis process\n",
    "plot_snapshots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_parameter_set(sep_proc_pair, boundary_strength, BEstabilization_factor, DSBstabilization_factor,longlived_fraction, super_loading_factor, proc_ratio,chrom_size, step_count_limit,alpha_list,boundary_coordinates,DSB_coordinates,LEF_step_probability,DSB_TAD_array_size, plot_snapshots = False):\n",
    "    \n",
    "    # assume uniform loading probability on the whole chromosome\n",
    "    loading_prob = np.ones(chrom_size)/chrom_size # the probability LEF loads at each lattice site on the chromosome\n",
    "    stall_prob_left = np.zeros(chrom_size, dtype=np.double) # numpy array to store the probability of left motor subunits of LEFs being stalled\n",
    "    stall_prob_right = np.zeros(chrom_size, dtype=np.double) # numpy array to store the probability of right motor subunits of LEFs being stalled\n",
    "    \n",
    "    separations = sep_proc_pair[0]\n",
    "    processivity = sep_proc_pair[1]\n",
    "    processivity_longlived = processivity * proc_ratio #processivity of long-lived LEFs\n",
    "    \n",
    "    # if boundary_strength is 0, there is no stabilization of LEF at BE\n",
    "    BEstabilization_factor_o = BEstabilization_factor \n",
    "    if boundary_strength == 0:\n",
    "        BEstabilization_factor = 1\n",
    "        \n",
    "    # list to store the first passage time\n",
    "    first_passage = []\n",
    "    # list to store the fraction of DSBs constrained by LEFs\n",
    "    restrained_fraction = []\n",
    "    # list to store fractions related to BE stabilization\n",
    "    stabilized_fraction = []\n",
    "    # list to store the size of last constraining LEF before it unloads for DSBs not synapsed\n",
    "    fail_gap_length_l = [] \n",
    "    # list to store the size of inner most constraining LEF when synapsis is achieved\n",
    "    success_gap_length_l = [] \n",
    "    \n",
    "    # deathProb, the probability that LEF unloads from chromosome\n",
    "    death_prob = np.zeros(chrom_size, dtype=np.double) + 1. / (0.5*processivity/(LEF_step_probability)) #times 0.5 to account for two-sided extrusion \n",
    "    death_prob_longlived = np.zeros(chrom_size, dtype=np.double) + 1. / (0.5*processivity_longlived/(LEF_step_probability)) # for super extruders\n",
    "    \n",
    "    # set the probability LEFs get stalled at lattice sites representing BE to be boundary strength\n",
    "    stall_prob_left[boundary_coordinates[::2]] = boundary_strength # odd elements of the boundary coordinates\n",
    "    stall_prob_right[boundary_coordinates[1::2]] = boundary_strength # even elements of the boundary coordinates\n",
    "    \n",
    "    # the probability that LEF does not take a step\n",
    "    pause_prob = (1-LEF_step_probability)*np.ones(chrom_size, dtype=np.double) \n",
    "\n",
    "    # the probability that LEF unloads at BE reduces if there is stabilization by BE\n",
    "    death_prob[boundary_coordinates] = 1./ (0.5*processivity/(LEF_step_probability))/ BEstabilization_factor\n",
    "    death_prob_longlived[boundary_coordinates] = 1./ (0.5*processivity_longlived/(LEF_step_probability))/ BEstabilization_factor\n",
    "    \n",
    "    # set the separations for normal LEFs and long-lived LEFs so that the separation for all LEFs matches the input parameter separation\n",
    "    normal_sep = separations/(1-longlived_fraction)\n",
    "    num_smcs = int(np.round(chrom_size/normal_sep))\n",
    "    if longlived_fraction==0:\n",
    "        num_smcs_super = 0\n",
    "    else:\n",
    "        super_sep = separations/longlived_fraction\n",
    "        num_smcs_super = int(np.round(chrom_size/super_sep))\n",
    "    \n",
    "    # create Boolean array for BE\n",
    "    boundary_coordinate_array = np.asarray(boundary_coordinates)\n",
    "    boundary_flag = np.zeros(chrom_size, int)\n",
    "    boundary_flag[boundary_coordinate_array] = 1 \n",
    "    \n",
    "    # create simulation object with parameters defined above\n",
    "    transloc = LEFTranslocatorDirectional(loading_prob, death_prob, death_prob_longlived, stall_prob_left, stall_prob_right,\\\n",
    "                                          pause_prob, num_smcs, boundary_flag,num_smcs_super) \n",
    "    \n",
    "    # number of simulation steps prior to DSB to take snapshots\n",
    "    preDSB_step_count_to_take_snapshots = 60\n",
    "    # let the system reach steady state\n",
    "    transloc.steps(100000-preDSB_step_count_to_take_snapshots)\n",
    "    \n",
    "    \n",
    "    # get LEF coordinates\n",
    "    super_left_extruders, super_right_extruders = transloc.getlonglivedLEFs()\n",
    "    normal_left_extruders, normal_right_extruders = transloc.getLEFs()\n",
    "    left_extruders  =  np.concatenate((super_left_extruders,normal_left_extruders))\n",
    "    right_extruders  =  np.concatenate((super_right_extruders,normal_right_extruders))\n",
    "    super_extruder_len = len(super_left_extruders)\n",
    "    \n",
    "    # lists to store gap sizes for plotting in snapshots\n",
    "    gapsize_list_left = [[] for i in range(int(len(DSB_coordinates)/2)//10+1)]\n",
    "    gapsize_list_right = [[] for i in range(int(len(DSB_coordinates)/2)//10+1)]\n",
    "    # lists of initial constraining LEF coordinates\n",
    "    constraining_left_o = np.zeros((int(len(DSB_coordinates)/2),1))\n",
    "    constraining_right_o = np.zeros((int(len(DSB_coordinates)/2),1))\n",
    "    #lists of initial gap sizes\n",
    "    gapsize_left_o = np.zeros((int(len(DSB_coordinates)/2),1))\n",
    "    gapsize_right_o = np.zeros((int(len(DSB_coordinates)/2),1))\n",
    "    \n",
    "    # parameters for taking snapshots\n",
    "    steps_per_frame = 6 # frequency of taking snapshots\n",
    "    extrusion_velocity = 1\n",
    "    upper_time_limit = 60 # upper time limit for taking snapshots in minutes\n",
    "    gapsize_xmin = 0\n",
    "    \n",
    "    preDSB_step_count = 0\n",
    "    # Boolean flag as input for plotting function\n",
    "    preDSB = True\n",
    "    while preDSB_step_count<=preDSB_step_count_to_take_snapshots:\n",
    "        # scan through all DSBs to check on the status of gap filling\n",
    "        for i in range(int(len(DSB_coordinates)/2)):\n",
    "\n",
    "            # identify the 2 adjacent BEs to the DSB\n",
    "            test = np.asarray(boundary_coordinates) - DSB_coordinates[i*2]\n",
    "            boundary_index = np.argmax(test>0)\n",
    "            left_boundary = boundary_coordinates[boundary_index-1]\n",
    "            right_boundary = boundary_coordinates[boundary_index]\n",
    "            break_site = DSB_coordinates[i*2] # the left side of the DSB (DSB represented by 2 coordinates)\n",
    "            \n",
    "            # obtain the index of LEF that constrain the break site, if there's any\n",
    "            test_left = left_extruders - break_site\n",
    "            test_right = right_extruders - (break_site+1)\n",
    "            test = np.multiply(test_left,test_right) \n",
    "            constraining_LEF_index = np.argwhere(test<0)\n",
    "            # identify the inner most constraining LEF\n",
    "            loop_size = np.abs(right_extruders[constraining_LEF_index] - left_extruders[constraining_LEF_index])\n",
    "            if len(loop_size)>0:\n",
    "                innermost_index = np.argmin(loop_size)\n",
    "\n",
    "                constraining_left = left_extruders[constraining_LEF_index[innermost_index]] \n",
    "                constraining_right = right_extruders[constraining_LEF_index[innermost_index]] \n",
    "\n",
    "                if preDSB_step_count==0:\n",
    "                    constraining_left_o[i] = constraining_left\n",
    "                    constraining_right_o[i] = constraining_right\n",
    "                    left_gap = np.ones(chrom_size)\n",
    "                    right_gap = np.ones(chrom_size)\n",
    "                    gapsize_left_o[i] = max(len(left_gap[int(constraining_left_o[i]):break_site]),len(left_gap[int(left_boundary):break_site]),300)\n",
    "                    gapsize_right_o[i] =max(len(right_gap[(break_site+1)+1:int(constraining_right_o[i])]),len(right_gap[(break_site+1)+1:int(right_boundary)]),300)\n",
    "            else:\n",
    "                constraining_left = []\n",
    "                constraining_right  = []\n",
    "                if preDSB_step_count==0:\n",
    "                    constraining_left_o[i] = left_boundary\n",
    "                    constraining_right_o[i] = right_boundary\n",
    "                    left_gap = np.ones(chrom_size)\n",
    "                    right_gap = np.ones(chrom_size)\n",
    "                    gapsize_left_o[i] = len(left_gap[int(constraining_left_o[i]):break_site])\n",
    "                    gapsize_right_o[i] = len(right_gap[(break_site+1)+1:int(constraining_right_o[i])])\n",
    "            if plot_snapshots:\n",
    "                # take snap shots \n",
    "                unconstrained = False\n",
    "                if i%10==0 and (preDSB_step_count%steps_per_frame==0):\n",
    "                    synapsed = False\n",
    "                    # create plotting folder if it doesn't exist\n",
    "                    plotting_folder = output_folder+'/snapshots_sep{}_proc{}_superportion{}_superproc{}_ctcf{}_dsb{}_superloading{}_bs{}_DSB{}'.format(separations,processivity,longlived_fraction,processivity_longlived,BEstabilization_factor_o,DSBstabilization_factor,super_loading_factor, boundary_strength,i)\n",
    "                    if not os.path.exists(plotting_folder):\n",
    "                        os.makedirs(plotting_folder)\n",
    "                    title = '{:.2f} minutes before DSB'.format((preDSB_step_count_to_take_snapshots-preDSB_step_count)/60*2) #asumming 1kb/s total extrusion speed\n",
    "                    file_path = plotting_folder + '/step{}.jpeg'.format(preDSB_step_count)\n",
    "                    plot_LEFs(file_path,processivity,left_extruders,right_extruders,left_boundary,right_boundary,constraining_left,constraining_right,constraining_left_o[i],constraining_right_o[i],break_site,title,super_extruder_len,gapsize_list_left[i//10],gapsize_list_right[i//10],gapsize_left_o[i],gapsize_right_o[i] , steps_per_frame,extrusion_velocity,upper_time_limit,unconstrained,synapsed,preDSB,gapsize_xmin)\n",
    "\n",
    "        # take another step\n",
    "        transloc.steps(1)\n",
    "        preDSB_step_count += 1\n",
    "        # update LEF positions\n",
    "        super_left_extruders, super_right_extruders = transloc.getlonglivedLEFs()\n",
    "        normal_left_extruders, normal_right_extruders = transloc.getLEFs()\n",
    "        left_extruders  =  np.concatenate((super_left_extruders,normal_left_extruders))\n",
    "        right_extruders  =  np.concatenate((super_right_extruders,normal_right_extruders))\n",
    "\n",
    "    \n",
    "\n",
    "    # list to store the maximum extrusion distance before each LEF unloads\n",
    "    extruded_len_list = []\n",
    "\n",
    "    # flag indicate whether the DSB is restrained at the time of DSB\n",
    "    restrained_time0 = np.ones(int(len(DSB_coordinates)/2)) # fraction of DSBs constrained by LEFs at the time of the DSB\n",
    "    restrained_realtime = np.ones(int(len(DSB_coordinates)/2)) # remaining fraction of DSBs constrained by LEFs (synapsed sites are considered constrained), updated throughout the simulation process\n",
    "    restrained_realtime_old = np.copy(restrained_realtime)\n",
    "    innerconstraining_LEF_size = np.zeros(int(len(DSB_coordinates)/2)) # size of innermost constraining LEF at each DSB site(if there's any)\n",
    "    # array to store LEF identities at DSBs\n",
    "    LEF_identity = np.zeros((5,int(len(DSB_coordinates)/2))) \n",
    "    # first row: constraining LEF identity: 0 if normal LEF, 1 if super LEF\n",
    "    # 2nd row: number of normal LEFs in the left gap\n",
    "    # 3rd row: number of longlived LEFs in the left gap\n",
    "    # 4th row: number of normal LEFs in the right gap\n",
    "    # 5th row: number of longlived LEFs in the right gap\n",
    "    \n",
    "    # time points for in silico ChIP\n",
    "    chip_timepoints = [120, 300, 600, 1800, 2700, 3600] # 4min, 10min, 20min, 60min, 90min, 2hr (assuming 1kb/s extrusion speed)\n",
    "    # array to store LEF coordiates across the indicated time points\n",
    "    # odd rows for left motor subunits, and even rows for right motor subunits\n",
    "    LEF_coordinates = np.zeros((14,len(left_extruders))) # number of LEFs in TADs when gap bridging finishes  \n",
    "    portion_TADs_with_stabilized_LEFs = 0\n",
    "    for i in range(int(len(boundary_coordinates)/2-1)):\n",
    "        left_boundary = boundary_coordinates[i*2]\n",
    "        right_boundary = boundary_coordinates[i*2+1]\n",
    "        \n",
    "        # record the fraction of TADs with stabilized LEFs\n",
    "        if (left_boundary in left_extruders) or (right_boundary in right_extruders):\n",
    "            portion_TADs_with_stabilized_LEFs += 1\n",
    "        \n",
    "    portion_TADs_with_stabilized_LEFs = portion_TADs_with_stabilized_LEFs/(len(boundary_coordinates)/2)\n",
    "    LEF_coordinates[0,:] =  left_extruders\n",
    "    LEF_coordinates[1,:] =  right_extruders\n",
    "        \n",
    "    # record the fraction of BE occupied by LEFs\n",
    "    test_1 = np.intersect1d(left_extruders,boundary_coordinates[::2]) \n",
    "    test_2 = np.intersect1d(right_extruders,boundary_coordinates[1::2]) \n",
    "    portion_BE_occupied_by_LEF = (len(test_1) + len(test_2))/len(boundary_coordinates)\n",
    "    \n",
    "    overlap = np.intersect1d(np.concatenate([np.argwhere(left_extruders==test1) for test1 in test_1 if len(np.argwhere(left_extruders==test1))>0]),np.concatenate([np.argwhere(right_extruders==test2) for test2 in test_2 if len(np.argwhere(right_extruders==test2))>0]))\n",
    "    portion_LEF_stabilized_by_BE = (len(test_1) + len(test_2)-len(overlap))/len(left_extruders) \n",
    "    \n",
    "    # record the fraction of normal LEFs stabilized by BE\n",
    "    test_1 = np.intersect1d(normal_left_extruders,boundary_coordinates[::2]) \n",
    "    test_2 = np.intersect1d(normal_right_extruders,boundary_coordinates[1::2]) \n",
    "    test_1_list = [np.argwhere(normal_left_extruders==test1) for test1 in test_1 if len(np.argwhere(normal_left_extruders==test1))>0]\n",
    "    test_2_list = [np.argwhere(normal_right_extruders==test2) for test2 in test_2 if len(np.argwhere(normal_right_extruders==test2))>0]\n",
    "    if len(test_1_list)>0:\n",
    "        test_1_array = np.concatenate(test_1_list)\n",
    "    if len(test_2_list)>0:\n",
    "        test_2_array = np.concatenate(test_2_list)\n",
    "    overlap = np.intersect1d(test_1_array,test_2_array)\n",
    "    portion_normal_LEF_stabilized_by_BE = (len(test_1) + len(test_2)-len(overlap))/len(normal_left_extruders) \n",
    "    \n",
    "    # record the fraction of long-lived LEFs stabilized by BE\n",
    "    test_1 = np.intersect1d(super_left_extruders,boundary_coordinates[::2]) \n",
    "    test_2 = np.intersect1d(super_right_extruders,boundary_coordinates[1::2]) \n",
    "    test_1_list = [np.argwhere(super_left_extruders==test1) for test1 in test_1 if len(np.argwhere(super_left_extruders==test1))>0]\n",
    "    test_2_list = [np.argwhere(super_right_extruders==test2) for test2 in test_2 if len(np.argwhere(super_right_extruders==test2))>0]\n",
    "    if len(test_1_list)>0:\n",
    "        test_1_array = np.concatenate(test_1_list)\n",
    "    if len(test_2_list)>0:\n",
    "        test_2_array = np.concatenate(test_2_list)\n",
    "    overlap = np.intersect1d(test_1_array,test_2_array)\n",
    "    if len(super_left_extruders)>0:\n",
    "        portion_super_LEF_stabilized_by_BE = (len(test_1) + len(test_2)-len(overlap))/len(super_left_extruders) \n",
    "    else:\n",
    "        portion_super_LEF_stabilized_by_BE = np.nan \n",
    "    \n",
    "    stabilized_fraction.append([portion_BE_occupied_by_LEF*100,\n",
    "                                portion_TADs_with_stabilized_LEFs*100,\n",
    "                              portion_LEF_stabilized_by_BE*100,\n",
    "                              portion_normal_LEF_stabilized_by_BE,\n",
    "                              portion_super_LEF_stabilized_by_BE])\n",
    "    \n",
    "    stabilized_df = pd.DataFrame(stabilized_fraction, \n",
    "             columns=['percent BE occupied by LEF ',\n",
    "                     'percent TADs with stabilized LEF',\n",
    "                     'percent LEF stabilized by BE',\n",
    "                     'percent normal LEF stabilized by BE',\n",
    "                     'percent super LEF stabilized by BE']) \n",
    "    \n",
    "    stabilized_df.to_csv(output_folder+'/stabilized_df_sep{}_proc{}_superportion{}_superproc{}_ctcf{}_dsb{}_superloading{}_bs{}.csv'.format(separations,processivity,longlived_fraction,processivity_longlived,BEstabilization_factor_o,DSBstabilization_factor,super_loading_factor, boundary_strength))\n",
    "\n",
    "    \n",
    "    # counter for steps taken since the introduction of DSB    \n",
    "    step_count = 0\n",
    "\n",
    "    #introduce the DSB\n",
    "    preDSB = False\n",
    "    # make double strand break site impermeable\n",
    "    stall_prob_left[DSB_coordinates[1::2]] = 1 # even elements of the DSB coordinates\n",
    "    stall_prob_right[DSB_coordinates[::2]] = 1 # odd elements of the DSB coordinates\n",
    "    # boosting by DSB\n",
    "    death_prob[DSB_coordinates] =1. / (0.5*processivity/(LEF_step_probability))/ DSBstabilization_factor\n",
    "    death_prob_longlived[DSB_coordinates] =1. / (0.5*processivity_longlived/(LEF_step_probability))/ DSBstabilization_factor\n",
    "\n",
    "    # DSB flag to ensure correct valency at DSB site: DSB can only stabilize one LEF\n",
    "    DSB_flag = np.zeros(chrom_size, int)\n",
    "    DSB_flag[DSB_coordinates] = 1 \n",
    "    transloc.updateStallprob(stall_prob_left,stall_prob_right)\n",
    "    transloc.updateDSBFlag(DSB_flag)\n",
    "    # implement targeted loading mechanism\n",
    "    loading_prob[DSB_coordinates]= 1/chrom_size*super_loading_factor\n",
    "    transloc.updateEmissionProb(loading_prob)\n",
    "\n",
    "    #flags to indicate gap exists at different threshold level for a subTAD in a given tile\n",
    "    gap_threshold_flag = np.ones((int(len(DSB_coordinates)/2),len(alpha_list)))\n",
    "\n",
    "    \n",
    "    while np.count_nonzero(gap_threshold_flag)>0 and np.count_nonzero(restrained_realtime)>0 and step_count<step_count_limit:\n",
    "        \n",
    "        # in silico ChIP experiment at specified time points\n",
    "        if step_count in chip_timepoints:\n",
    "                row_num = (np.where(np.asarray(chip_timepoints)==step_count)[0]+1)*2\n",
    "                LEF_coordinates[row_num,:]=left_extruders\n",
    "                LEF_coordinates[row_num+1,:]=right_extruders\n",
    "                \n",
    "         # remove half of gap sizes when reaching upper_time_limit\n",
    "        if (step_count*2/extrusion_velocity/60)%(upper_time_limit/2)==0 and (step_count*2/extrusion_velocity/60)>= upper_time_limit:\n",
    "            for p in range(len(gapsize_list_left)):\n",
    "                del gapsize_list_left[p][0:int((upper_time_limit/2)*60*extrusion_velocity/2/steps_per_frame)]\n",
    "                del gapsize_list_right[p][0:int((upper_time_limit/2)*60*extrusion_velocity/2/steps_per_frame)]\n",
    "            gapsize_xmin += upper_time_limit/2\n",
    "        #scan through all the subTADs to check on the status of gap filling\n",
    "        for i in range(int(len(DSB_coordinates)/2)):\n",
    "\n",
    "            test = np.asarray(boundary_coordinates) - DSB_coordinates[i*2]\n",
    "            boundary_index = np.argmax(test>0)\n",
    "            left_boundary = boundary_coordinates[boundary_index-1]\n",
    "            right_boundary = boundary_coordinates[boundary_index]\n",
    "            break_site = DSB_coordinates[i*2] # the left side of the DSB (DSB represented by 2 coordinates)\n",
    "            \n",
    "\n",
    "            # obtain the index of LEF that constrain the DSB site, if there's any\n",
    "            test_left = left_extruders - break_site\n",
    "            test_right = right_extruders - (break_site+1)\n",
    "            test = np.multiply(test_left,test_right) \n",
    "            constraining_LEF_index = np.argwhere(test<0)\n",
    "\n",
    "            # check if two DSB ends are restrained and that there's gap with the specific threshold\n",
    "            if len(constraining_LEF_index)==0 and np.count_nonzero(gap_threshold_flag[i,:])>0:\n",
    "                restrained_realtime[i]=0\n",
    "                \n",
    "                if step_count == 0:\n",
    "                    restrained_time0[i]=0\n",
    "                    fail_gap_length_l+=[0]\n",
    "                elif restrained_realtime_old[i] == 1:\n",
    "                    fail_gap_length_l+=[innerconstraining_LEF_size[i]]\n",
    "            \n",
    "            if plot_snapshots:\n",
    "                if i%10==0:\n",
    "                    if restrained_realtime_old[i]==1 and restrained_realtime[i]==0:\n",
    "                        unconstrained = True\n",
    "                        synapsed = False\n",
    "                        title = '{:.2f} minutes after DSB'.format(step_count/60*2) #asumming 1kb/s total extrusion speed\n",
    "                        file_path = plotting_folder + '/step{}.jpeg'.format(step_count+preDSB_step_count_to_take_snapshots+1)\n",
    "                        if unconstrained:\n",
    "                            constraining_left = []\n",
    "                            constraining_right = []\n",
    "                        plot_LEFs(file_path,processivity,left_extruders,right_extruders,left_boundary,right_boundary,constraining_left,constraining_right,constraining_left_o[i],constraining_right_o[i],break_site,title,super_extruder_len,gapsize_list_left[i//10],gapsize_list_right[i//10],gapsize_left_o[i],gapsize_right_o[i] , steps_per_frame,extrusion_velocity,upper_time_limit,unconstrained,synapsed,preDSB,gapsize_xmin)\n",
    "\n",
    "\n",
    "            if restrained_realtime[i]==1: \n",
    "                unconstrained = False\n",
    "                if gap_threshold_flag[i,0]==1: # if the most stringent synapsis criteria is not yet met\n",
    "                    # identify the inner most constraining LEF\n",
    "                    loop_size = np.abs(right_extruders[constraining_LEF_index] - left_extruders[constraining_LEF_index])\n",
    "                    innermost_index = np.argmin(loop_size)\n",
    "\n",
    "                    constraining_left = left_extruders[constraining_LEF_index[innermost_index]] \n",
    "                    constraining_right = right_extruders[constraining_LEF_index[innermost_index]] \n",
    "                    innerconstraining_LEF_size[i] = constraining_right-constraining_left\n",
    "\n",
    "                    left_gap = np.ones(chrom_size)\n",
    "                    right_gap = np.ones(chrom_size)\n",
    "                    unfilled_gap_left = len(left_gap[constraining_left[0]+1:break_site])\n",
    "                    unfilled_gap_right = len(right_gap[(break_site+1)+1:constraining_right[0]])\n",
    "\n",
    "                    # test for the left side of the break\n",
    "                    # find the LEFs between the left foot of the innermost restraing LEF and the break site\n",
    "                    test_left_1 = np.where((left_extruders-constraining_left)>=0,1,0) \n",
    "                    test_left_2 = np.where((right_extruders-break_site)<=0,1,0)\n",
    "                    test_left = np.multiply(test_left_1,test_left_2) \n",
    "                    left_between_index = np.argwhere(test_left==1)\n",
    "                    # continue to test for the right side of the break\n",
    "                    # find the LEFs between the break site and the right foot of the innermost restraing LEF \n",
    "                    test_right_1 = np.where((left_extruders-(break_site+1))>=0,1,0) \n",
    "                    test_right_2 = np.where((right_extruders-constraining_right)<=0,1,0)\n",
    "                    test_right = np.multiply(test_right_1,test_right_2) \n",
    "                    right_between_index = np.argwhere(test_right==1)\n",
    "\n",
    "                    if len(left_between_index)>0:\n",
    "\n",
    "                        for j in range(len(left_between_index)):\n",
    "                            left_gap[left_extruders[left_between_index[j]][0]:(right_extruders[left_between_index[j]][0]+1)]=0\n",
    "\n",
    "                        unfilled_gap_left = np.count_nonzero(left_gap[constraining_left[0]+1:break_site])\n",
    "\n",
    "                    if len(right_between_index)>0:\n",
    "\n",
    "                        for j in range(len(right_between_index)):\n",
    "                            right_gap[left_extruders[right_between_index[j]][0]:(right_extruders[right_between_index[j]][0]+1)]=0\n",
    "\n",
    "                        unfilled_gap_right = np.count_nonzero(right_gap[(break_site+1)+1:constraining_right[0]])\n",
    "\n",
    "                    if plot_snapshots:\n",
    "                        #take snap shots (randomly select ~20 DSB sites for snapshots every steps_per_frame steps) \n",
    "                        synapsed = False\n",
    "                        if unfilled_gap_left <= alpha_list[0]*2 and unfilled_gap_right <= alpha_list[0]*2:\n",
    "                            synapsed = True\n",
    "                        if i%10==0 and (step_count%steps_per_frame==0 or synapsed):\n",
    "\n",
    "                            gapsize_list_left[i//10]+=[unfilled_gap_left]\n",
    "                            gapsize_list_right[i//10]+=[unfilled_gap_right]\n",
    "                            # create plotting folder if it doesn't exist\n",
    "                            plotting_folder = output_folder+'/snapshots_sep{}_proc{}_superportion{}_superproc{}_ctcf{}_dsb{}_superloading{}_bs{}_DSB{}'.format(separations,processivity,longlived_fraction,processivity_longlived,BEstabilization_factor_o,DSBstabilization_factor,super_loading_factor, boundary_strength,i)\n",
    "                            if not os.path.exists(plotting_folder):\n",
    "                                os.makedirs(plotting_folder)\n",
    "                            title = '{:.2f} minutes after DSB'.format(step_count/60*2) #asumming 1kb/s total extrusion speed\n",
    "                            file_path = plotting_folder + '/step{}.jpeg'.format(step_count+preDSB_step_count_to_take_snapshots+1)\n",
    "                            plot_LEFs(file_path,processivity,left_extruders,right_extruders,left_boundary,right_boundary,constraining_left,constraining_right,constraining_left_o[i],constraining_right_o[i],break_site,title,super_extruder_len,gapsize_list_left[i//10],gapsize_list_right[i//10],gapsize_left_o[i],gapsize_right_o[i] , steps_per_frame,extrusion_velocity,upper_time_limit,unconstrained,synapsed,preDSB,gapsize_xmin)\n",
    "\n",
    "                    for k in range(len(alpha_list)):\n",
    "                        # check if the gap has been filled on this threshold level\n",
    "                        if gap_threshold_flag[i,k]==1:\n",
    "\n",
    "                            if unfilled_gap_left <= alpha_list[k]*2 and unfilled_gap_right <= alpha_list[k]*2: # To speed up computation, only look at the gap on the right if the gap on the left meets threshold\n",
    "\n",
    "                                # record the number of LEFs in each DSB-induced sub_TAD\n",
    "                                # find the LEFs between the left_boundary and the right_boundary\n",
    "                                test_1 = np.where((left_extruders-left_boundary)*(left_extruders-right_boundary)<=0,1,0) \n",
    "                                test_2 = np.where((right_extruders-left_boundary)*(right_extruders-right_boundary)<=0,1,0) \n",
    "                                test_binary = np.multiply(test_1,test_2) \n",
    "                                between_index = np.argwhere(test_binary==1)\n",
    "                                num_LEFs_between = np.count_nonzero(test_1)+np.count_nonzero(test_2)-len(between_index)\n",
    "\n",
    "                                # obtain further info on the DSB\n",
    "                                if i == 0:\n",
    "                                    dist_to_neighbor_DSB = DSB_coordinates[(i+1)*2] - break_site\n",
    "                                elif i==len(DSB_coordinates)/2-1:\n",
    "                                    dist_to_neighbor_DSB = break_site - DSB_coordinates[(i-1)*2]\n",
    "                                else:\n",
    "                                    dist_to_neighbor_DSB = DSB_coordinates[(i+1)*2] - DSB_coordinates[(i-1)*2]\n",
    "\n",
    "                                # record LEF identity\n",
    "                                if constraining_right[0] in super_right_extruders:\n",
    "                                    LEF_identity[0,i] = 1\n",
    "                                # find the normal LEFs in the left gap \n",
    "                                test_1 = np.where((normal_left_extruders-constraining_left)>=0,1,0) \n",
    "                                test_2 = np.where((normal_right_extruders-break_site)<=0,1,0)\n",
    "                                test = np.multiply(test_1,test_2) \n",
    "                                left_between_normal_index = np.argwhere(test==1)\n",
    "                                LEF_identity[1,i] = len(left_between_normal_index)\n",
    "                                # find the longlived LEFs in the left gap \n",
    "                                test_1 = np.where((super_left_extruders-constraining_left)>=0,1,0) \n",
    "                                test_2 = np.where((super_right_extruders-break_site)<=0,1,0)\n",
    "                                test = np.multiply(test_1,test_2) \n",
    "                                left_between_super_index = np.argwhere(test==1)\n",
    "                                LEF_identity[2,i] = len(left_between_super_index)\n",
    "                                # find the normal LEFs in the right gap \n",
    "                                test_1 = np.where((normal_left_extruders-(break_site+1))>=0,1,0) \n",
    "                                test_2 = np.where((normal_right_extruders-constraining_right)<=0,1,0)\n",
    "                                test = np.multiply(test_1,test_2) \n",
    "                                right_between_normal_index = np.argwhere(test==1)\n",
    "                                LEF_identity[3,i] = len(right_between_normal_index)\n",
    "                                # find the longlived LEFs in the right gap \n",
    "                                test_1 = np.where((super_left_extruders-(break_site+1))>=0,1,0) \n",
    "                                test_2 = np.where((super_right_extruders-constraining_right)<=0,1,0)\n",
    "                                test = np.multiply(test_1,test_2) \n",
    "                                right_between_super_index = np.argwhere(test==1)\n",
    "                                LEF_identity[4,i] = len(right_between_super_index)\n",
    "\n",
    "                                dist_to_CTCF = break_site - left_boundary\n",
    "                                subTAD_size = right_boundary - left_boundary\n",
    "\n",
    "                                first_passage.append([separations,\n",
    "                                                      processivity,\n",
    "                                                      boundary_strength,\n",
    "                                                      subTAD_size,\n",
    "                                                      alpha_list[k],\n",
    "                                                      step_count,\n",
    "                                                    num_LEFs_between,\n",
    "                                                    dist_to_neighbor_DSB,\n",
    "                                                     dist_to_CTCF])\n",
    "\n",
    "                                gap_threshold_flag[i,k] = 0\n",
    "                                if k==0:\n",
    "                                    success_gap_length_l += [innerconstraining_LEF_size[i]]\n",
    "\n",
    "\n",
    "        # take another step\n",
    "        transloc.steps(1)\n",
    "        step_count += 1\n",
    "        #time_recorder += 1\n",
    "        # store the position of left motor subunits\n",
    "        old_left_extruders = left_extruders\n",
    "        old_right_extruders = right_extruders\n",
    "        #update LEF positions\n",
    "        super_left_extruders, super_right_extruders = transloc.getlonglivedLEFs()\n",
    "        normal_left_extruders, normal_right_extruders = transloc.getLEFs()\n",
    "        left_extruders  =  np.concatenate((super_left_extruders,normal_left_extruders))\n",
    "        right_extruders  =  np.concatenate((super_right_extruders,normal_right_extruders))\n",
    "\n",
    "        # identify the extruders that have been unloaded\n",
    "        diff = abs(old_left_extruders-left_extruders)\n",
    "        unloaded_index = np.argwhere(diff>1)\n",
    "        extruded_len =[old_right_extruders[i]-old_left_extruders[i] for i in range(len(unloaded_index))]\n",
    "        extruded_len_list += extruded_len\n",
    "        \n",
    "        restrained_realtime_old = np.copy(restrained_realtime)\n",
    "        \n",
    "    # reverse the DSB for the next round of simulation (not necessary for parallel implementation)\n",
    "    stall_prob_left[DSB_coordinates] = 0\n",
    "    stall_prob_right[DSB_coordinates] = 0\n",
    "    \n",
    "    death_prob = np.zeros(chrom_size, dtype=np.double) + 1. / (0.5*processivity/(LEF_step_probability)) \n",
    "    death_prob_longlived = np.zeros(chrom_size, dtype=np.double) + 1. / (0.5*processivity_longlived/(LEF_step_probability)) \n",
    "    \n",
    "    DSB_flag = np.zeros(chrom_size, int)\n",
    "    loading_prob = np.ones(chrom_size)/chrom_size\n",
    "    \n",
    "    # record simulation data associated with a specific distance threshold alpha (note some of these are independent of alpha)\n",
    "    for k in range(len(alpha_list)):\n",
    "        success_index = np.nonzero(gap_threshold_flag[:,k]-1) # index of the DSBs synapsed at this distance threshold\n",
    "        restrained_time0_index = np.nonzero(restrained_time0[:]) # index of DSB constrained at the time of DSB\n",
    "        restrained_index = np.nonzero(restrained_realtime[:]) # index of remaining DSB that are constrained, updated throughout simulation\n",
    "        success_TAD_sizes = DSB_TAD_array_size[success_index] # array of TAD sizes containing synapsed DSB\n",
    "        restrained_time0_TAD_sizes = DSB_TAD_array_size[restrained_time0_index] # array of TAD sizes containing DSBs that are constrained at the time of DSB induction\n",
    "        restrained_TAD_sizes = DSB_TAD_array_size[restrained_index] # array of TAD sizes containing DSBs that are synapsed or remained constrained throughout simulation\n",
    "        DSB_count = np.count_nonzero(DSB_TAD_array_size) # total number of DSB sites\n",
    "        success_200kb = len(np.argwhere(success_TAD_sizes==200)) # number of 200kb TADs containing synapsed DSB\n",
    "        success_400kb = len(np.argwhere(success_TAD_sizes==400)) # number of 400kb TADs containing synapsed DSB\n",
    "        success_800kb = len(np.argwhere(success_TAD_sizes==800)) # number of 800kb TADs containing synapsed DSB\n",
    "        success_1200kb = len(np.argwhere(success_TAD_sizes==1200)) # number of 1200kb TADs containing synapsed DSB\n",
    "        restrained_time0_200kb = len(np.argwhere(restrained_time0_TAD_sizes==200)) # number of 200kb TADs containing whose DSB is constrained when induced\n",
    "        restrained_time0_400kb = len(np.argwhere(restrained_time0_TAD_sizes==400)) # number of 400kb TADs containing whose DSB is constrained when induced\n",
    "        restrained_time0_800kb = len(np.argwhere(restrained_time0_TAD_sizes==800)) # number of 800kb TADs containing whose DSB is constrained when induced\n",
    "        restrained_time0_1200kb = len(np.argwhere(restrained_time0_TAD_sizes==1200)) # number of 1200kb TADs containing whose DSB is constrained when induced\n",
    "        restrained_200kb = len(np.argwhere(restrained_TAD_sizes==200)) # number of 200kb TADs containing whose DSB is synapsed or remained constrained throughout simulation\n",
    "        restrained_400kb = len(np.argwhere(restrained_TAD_sizes==400)) # number of 400kb TADs containing whose DSB is synapsed or remained constrained throughout simulation\n",
    "        restrained_800kb = len(np.argwhere(restrained_TAD_sizes==800)) # number of 800kb TADs containing whose DSB is synapsed or remained constrained throughout simulation\n",
    "        restrained_1200kb = len(np.argwhere(restrained_TAD_sizes==1200)) # number of 1200kb TADs containing whose DSB is synapsed or remained constrained throughout simulation\n",
    "        restrained_fraction.append([separations,\n",
    "                                    processivity,\n",
    "                                    boundary_strength,\n",
    "                                    alpha_list[k], \n",
    "                                    np.count_nonzero(restrained_time0[:])/DSB_count,\n",
    "                                    np.count_nonzero(restrained_realtime[:])/DSB_count,\n",
    "                                    len(success_index[0]),\n",
    "                                    len(success_index[0])/ DSB_count,\n",
    "                                    restrained_time0_200kb,\n",
    "                                    restrained_time0_400kb,\n",
    "                                    restrained_time0_800kb,\n",
    "                                    restrained_time0_1200kb,\n",
    "                                    restrained_200kb,\n",
    "                                    restrained_400kb,\n",
    "                                    restrained_800kb,\n",
    "                                    restrained_1200kb,\n",
    "                                    success_200kb,\n",
    "                                    success_400kb,\n",
    "                                    success_800kb,\n",
    "                                    success_1200kb,\n",
    "                                    np.mean(extruded_len_list),\n",
    "                                     portion_BE_occupied_by_LEF*100,\n",
    "                                     portion_TADs_with_stabilized_LEFs*100,\n",
    "                                     portion_LEF_stabilized_by_BE*100])\n",
    "        \n",
    "\n",
    "    restrained_df = pd.DataFrame(restrained_fraction, \n",
    "             columns=['separations',\n",
    "                      'processivity',\n",
    "                      'boundary strength',\n",
    "                      'threshold',\n",
    "                      'restrained proportion time0',\n",
    "                    'restrained proportion realtime',\n",
    "                     'successful repair count',\n",
    "                     'repaired proportion',\n",
    "                      'initial restrained 200kb count',\n",
    "                     'initial restrained 400kb count',\n",
    "                     'initial restrained 800kb count',\n",
    "                     'initial restrained 1200kb count',\n",
    "                      'realtime restrained 200kb count',\n",
    "                     'realtime restrained 400kb count',\n",
    "                     'realtime restrained 800kb count',\n",
    "                     'realtime restrained 1200kb count',\n",
    "                    'repaired 200kb count',\n",
    "                     'repaired 400kb count',\n",
    "                     'repaired 800kb count',\n",
    "                     'repaired 1200kb count',\n",
    "                     'average extruded length',\n",
    "                     'portion_BE_occupied_by_LEF',\n",
    "                     'portion_TADs_with_stabilized_LEFs',\n",
    "                     'portion_LEF_stabilized_by_BE']) \n",
    "\n",
    "\n",
    "\n",
    "    stats_df = pd.DataFrame(first_passage, \n",
    "                     columns=['separations',\n",
    "                              'processivity',\n",
    "                              'boundary_strength',\n",
    "                              'TAD_size',\n",
    "                              'threshold',\n",
    "                              'first_passage_time',\n",
    "                             'subTAD_LEFs_num',\n",
    "                             'dist_to_neighbor_DSB',\n",
    "                             'dist_to_CTCF']) \n",
    "\n",
    "\n",
    "    restrained_df.to_csv(output_folder+'/restrained_df_sep{}_proc{}_superportion{}_superproc{}_ctcf{}_dsb{}_superloading{}_bs{}.csv'.format(separations,processivity,longlived_fraction,processivity_longlived,BEstabilization_factor_o,DSBstabilization_factor,super_loading_factor, boundary_strength))\n",
    "    stats_df.to_csv(output_folder+'/stats_df_sep{}_proc{}_superportion{}_superproc{}_ctcf{}_dsb{}_superloading{}_bs{}.csv'.format(separations,processivity,longlived_fraction,processivity_longlived,BEstabilization_factor_o,DSBstabilization_factor,super_loading_factor,boundary_strength))\n",
    "    \n",
    "    file = output_folder+'/GapLength_sep{}_proc{}_superportion{}_superproc{}_ctcf{}_dsb{}_superloading{}_bs{}.npy'.format(separations,processivity,longlived_fraction,processivity_longlived,BEstabilization_factor_o,DSBstabilization_factor,super_loading_factor, boundary_strength)\n",
    "    # saving gap lengths\n",
    "    with open(file, 'wb') as g:\n",
    "        np.save(g, np.asarray(fail_gap_length_l))\n",
    "        np.save(g, np.asarray(success_gap_length_l))\n",
    "        \n",
    "    # save the distribution of LEFs in different TAD sizes\n",
    "    file = output_folder+'/LEFcoordinates_sep{}_proc{}_superportion{}_superproc{}_ctcf{}_dsb{}_superloading{}_bs{}.npy'.format(separations,processivity,longlived_fraction,processivity_longlived,BEstabilization_factor_o,DSBstabilization_factor,super_loading_factor,boundary_strength)\n",
    "    # saving LEF counts\n",
    "    with open(file, 'wb') as g:\n",
    "        np.save(g, LEF_coordinates)\n",
    "    \n",
    "    file = output_folder+'/LEFidentity_sep{}_proc{}_superportion{}_superproc{}_ctcf{}_dsb{}_superloading{}_bs{}.npy'.format(separations,processivity,longlived_fraction,processivity_longlived,BEstabilization_factor_o,DSBstabilization_factor,super_loading_factor,boundary_strength)\n",
    "    # saving gap lengths\n",
    "    with open(file, 'wb') as g:\n",
    "        np.save(g, LEF_identity)\n",
    "    \n",
    "    return None\n",
    "\n",
    "   \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "num_cores = 30\n",
    "\n",
    "generator_of_inputs = product(sep_proc_list, boundary_strength_list,BE_stabilization_factor_list, DSB_stabilization_factor_list,longlived_fraction_list,targetedloading_factor_list)\n",
    "\n",
    "# create independent copies of the shared parameters\n",
    "inputs = [(a,b,c,d,e,f,proc_ratio, chrom_size,step_count_limit,alpha_list,boundary_coordinates,DSB_coordinates,LEF_step_probability,DSB_TAD_array_size, plot_snapshots) for a,b,c,d,e,f in generator_of_inputs]\n",
    "\n",
    "pool = Pool(num_cores)\n",
    "\n",
    "results = pool.starmap(do_one_parameter_set, inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
